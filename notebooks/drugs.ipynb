{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.7 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Drugs_Ratings_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "853417d72ad81a5e50a8613ae15c38dd8101027062a267a28f225259147f3710"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "module_path = os.path.abspath(os.path.join('..'))\r\n",
        "if module_path not in sys.path:\r\n",
        "    sys.path.append(module_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import time\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "\r\n",
        "from lmmnn.layers import NLL\r\n",
        "from lmmnn.callbacks import EarlyStoppingWithSigmasConvergence\r\n",
        "from lmmnn.menet import menet_fit, menet_predict\r\n",
        "from lmmnn.simulation import Count\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing import text, sequence\r\n",
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Reshape, Concatenate, Input, Layer, Dropout, Flatten\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\r\n",
        "import tensorflow.keras.backend as K"
      ],
      "outputs": [],
      "metadata": {
        "id": "nz7b58k2WgZg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\r\n",
        "for gpu in gpus:\r\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "H_bWJVbwWgZg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# The drugs_df CSV comes from simple binding the train and test TSVs from Gräßer et al. (2018),\r\n",
        "# available in the UCI ML repo, see our paper.\r\n",
        "drugs = pd.read_csv('drugs_df.csv')\r\n",
        "RE_col = 'drug_name'"
      ],
      "outputs": [],
      "metadata": {
        "id": "lsV53IjcawCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "drugs.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                  drugName                     condition  \\\n",
              "0  206461                 Valsartan  Left Ventricular Dysfunction   \n",
              "1   95260                Guanfacine                          ADHD   \n",
              "2   92703                    Lybrel                 Birth Control   \n",
              "3  138000                Ortho Evra                 Birth Control   \n",
              "4   35696  Buprenorphine / naloxone             Opiate Dependence   \n",
              "\n",
              "                                              review  rating  \\\n",
              "0  \"It has no side effect, I take it in combinati...       9   \n",
              "1  \"My son is halfway through his fourth week of ...       8   \n",
              "2  \"I used to take another oral contraceptive, wh...       5   \n",
              "3  \"This is my first time using any form of birth...       8   \n",
              "4  \"Suboxone has completely turned my life around...       9   \n",
              "\n",
              "                date  usefulCount  drug_name  \n",
              "0       May 20, 2012           27       3428  \n",
              "1     April 27, 2010          192       1542  \n",
              "2  December 14, 2009           17       1989  \n",
              "3   November 3, 2015           10       2456  \n",
              "4  November 27, 2016           37        553  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>drug_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206461</td>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>9</td>\n",
              "      <td>May 20, 2012</td>\n",
              "      <td>27</td>\n",
              "      <td>3428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95260</td>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>8</td>\n",
              "      <td>April 27, 2010</td>\n",
              "      <td>192</td>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92703</td>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>5</td>\n",
              "      <td>December 14, 2009</td>\n",
              "      <td>17</td>\n",
              "      <td>1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>138000</td>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"This is my first time using any form of birth...</td>\n",
              "      <td>8</td>\n",
              "      <td>November 3, 2015</td>\n",
              "      <td>10</td>\n",
              "      <td>2456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35696</td>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Suboxone has completely turned my life around...</td>\n",
              "      <td>9</td>\n",
              "      <td>November 27, 2016</td>\n",
              "      <td>37</td>\n",
              "      <td>553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "3k-26fe-WgZh",
        "outputId": "7ae790f7-947b-4d13-ede7-02b982bf42b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "max_features = 10000\r\n",
        "batch_size = 20\r\n",
        "epochs = 10\r\n",
        "seq_len = 100\r\n",
        "words_embed_dim = 100\r\n",
        "Z_embed_dim = 10\r\n",
        "lstm_kernels = 64\r\n",
        "n_cats = drugs[RE_col].max() + 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "wtxphUSvWgZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "n_cats"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3671"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqg-BtSgWgZj",
        "outputId": "5eb3e3e9-a980-4051-a3fd-118d00e6be3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "drugs[RE_col].min()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2l6DPWWgZk",
        "outputId": "a024b5a3-b248-4127-ef47-8ab0996ea2ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "drugs[RE_col].max()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn4vTU8cWgZk",
        "outputId": "ef020809-6d9e-405f-8e04-ddfd03bf452e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\r\n",
        "tokenizer.fit_on_texts(drugs['review'])\r\n",
        "text_sequences = tokenizer.texts_to_sequences(drugs['review'])\r\n",
        "X = sequence.pad_sequences(text_sequences, padding='post', maxlen=seq_len)\r\n",
        "X = pd.DataFrame(X)\r\n",
        "x_cols = ['X' + str(i) for i in range(seq_len)]\r\n",
        "X.columns = x_cols\r\n",
        "X = pd.concat([X, drugs[RE_col]], axis=1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DWNy52KjWgZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "X.loc[0, x_cols].values"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   5,   38,   28,   35,  198,    1,   45,    5,   15,  832,   12,\n",
              "       2948,   99,  149,    2, 3852, 1585,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8ftYpoyWgZk",
        "outputId": "35404164-c853-4dd5-95da-dbdd3ff15831"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "((X[x_cols] > 0).astype(int).sum(axis=1) == seq_len).mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.427009759930811"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGLYZYXUWgZl",
        "outputId": "592c3e48-8c4b-41ac-e530-3925d6166302"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "drugs.loc[0, 'review']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lJ4pVhZ1WgZl",
        "outputId": "4fcf6145-e9c1-4bac-8ec1-79a2390aedc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "tokenizer.word_index['it']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRTKb4VWgZl",
        "outputId": "de37f9e5-7f09-4ca5-840d-de692da53f7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "def lstm_ignore():\r\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\r\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\r\n",
        "    x = LSTM(lstm_kernels)(x)\r\n",
        "    output = Dense(1)(x)\r\n",
        "    return Model(inputs=[input_layer], outputs=output)\r\n",
        "\r\n",
        "def lstm_lmmnn():\r\n",
        "    input_layer = Input(shape=(seq_len, ), dtype=tf.int32)\r\n",
        "    y_true_input = Input(shape=(1, ),)\r\n",
        "    Z_input = Input(shape=(1, ), dtype=tf.int64)\r\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\r\n",
        "    x = LSTM(lstm_kernels)(x)\r\n",
        "    y_pred_output = Dense(1)(x)\r\n",
        "    nll = NLL('intercepts', 1.0, [1.0])(y_true_input, y_pred_output, [Z_input])\r\n",
        "    return Model(inputs=[input_layer, y_true_input, Z_input], outputs=nll)\r\n",
        "\r\n",
        "def lstm_embed():\r\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\r\n",
        "    Z_input = Input(shape=(1,))\r\n",
        "    embed = Embedding(n_cats, Z_embed_dim, input_length = 1)(Z_input)\r\n",
        "    embed = Reshape(target_shape = (Z_embed_dim, ))(embed)\r\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\r\n",
        "    x = LSTM(lstm_kernels)(x)\r\n",
        "    concat = Concatenate()([x, embed])\r\n",
        "    output = Dense(1)(concat)\r\n",
        "    return Model(inputs=[input_layer, Z_input], outputs=output)\r\n",
        "\r\n",
        "def lstm_ohe(p):\r\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\r\n",
        "    ohe_input = Input(shape=(p, ))\r\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\r\n",
        "    x = LSTM(lstm_kernels)(x)\r\n",
        "    concat = Concatenate()([x, ohe_input])\r\n",
        "    output = Dense(1)(concat)\r\n",
        "    return Model(inputs=[input_layer, ohe_input], outputs=output)"
      ],
      "outputs": [],
      "metadata": {
        "id": "R3Q35JCiWgZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "def calc_b_hat(Z_train, y_train, y_pred_tr, n_cats, sig2e, sig2bs):\r\n",
        "    sig2b = sig2bs[0]\r\n",
        "    b_hat = []\r\n",
        "    for i in range(n_cats):\r\n",
        "        i_vec = Z_train == i\r\n",
        "        n_i = i_vec.sum()\r\n",
        "        if n_i > 0:\r\n",
        "            y_bar_i = y_train[i_vec].mean()\r\n",
        "            y_pred_i = y_pred_tr[i_vec].mean()\r\n",
        "            # BP(b_i) = (n_i * sig2b / (sig2a + n_i * sig2b)) * (y_bar_i - y_pred_bar_i)\r\n",
        "            b_i = n_i * sig2b * (y_bar_i - y_pred_i) / (sig2e + n_i * sig2b)\r\n",
        "        else:\r\n",
        "            b_i = 0\r\n",
        "        b_hat.append(b_i)\r\n",
        "    return np.array(b_hat)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MaqoyIpBWgZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def process_one_hot_encoding(X_train, X_test, RE_col):\r\n",
        "    X_train_ohe = pd.concat([X_train[x_cols], pd.get_dummies(X_train[RE_col])], axis=1)\r\n",
        "    X_test_ohe = pd.concat([X_test[x_cols], pd.get_dummies(X_test[RE_col])], axis=1)\r\n",
        "    X_test_cols_in_train = set(X_test_ohe.columns).intersection(X_train_ohe.columns)\r\n",
        "    X_train_cols_not_in_test = set(X_train_ohe.columns).difference(X_test_ohe.columns)\r\n",
        "    X_test_comp = pd.DataFrame(np.zeros((X_test.shape[0], len(X_train_cols_not_in_test))),\r\n",
        "                               columns=X_train_cols_not_in_test, dtype=np.uint8, index=X_test.index)\r\n",
        "    X_test_ohe_comp = pd.concat([X_test_ohe[X_test_cols_in_train], X_test_comp], axis=1)\r\n",
        "    X_test_ohe_comp = X_test_ohe_comp[X_train_ohe.columns]\r\n",
        "    return X_train_ohe, X_test_ohe_comp"
      ],
      "outputs": [],
      "metadata": {
        "id": "bPnvvceLWgZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "def reg_nn_ignore(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False, verbose=False):\r\n",
        "    model = lstm_ignore()\r\n",
        "    model.compile(loss='mse', optimizer='adam')\r\n",
        "\r\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\r\n",
        "    history = model.fit(X_train[x_cols], y_train, batch_size=batch_size, epochs=epochs,\r\n",
        "                        validation_split=0.1, callbacks=callbacks, verbose=verbose)\r\n",
        "    y_pred = model.predict(X_test[x_cols]).reshape(X_test.shape[0])\r\n",
        "    y_pred = np.clip(y_pred, 1, 10)\r\n",
        "    return y_pred, (None, None), len(history.history['loss'])\r\n",
        "\r\n",
        "def reg_nn_ohe(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False, verbose=False):\r\n",
        "    X_train, X_test = process_one_hot_encoding(X_train, X_test, RE_col)\r\n",
        "    model = lstm_ohe(X_train.drop(x_cols, axis=1).shape[1])\r\n",
        "    model.compile(loss='mse', optimizer='adam')\r\n",
        "\r\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\r\n",
        "    history = model.fit([X_train[x_cols], X_train.drop(x_cols, axis=1)], y_train, batch_size=batch_size, epochs=epochs,\r\n",
        "                        validation_split=0.1, callbacks=callbacks, verbose=verbose)\r\n",
        "    y_pred = model.predict([X_test[x_cols], X_test.drop(x_cols, axis=1)]).reshape(X_test.shape[0])\r\n",
        "    y_pred = np.clip(y_pred, 1, 10)\r\n",
        "    return y_pred, (None, None), len(history.history['loss'])\r\n",
        "\r\n",
        "def reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False, verbose=False):\r\n",
        "    model = lstm_lmmnn()\r\n",
        "    model.compile(optimizer= 'adam')\r\n",
        "    \r\n",
        "    patience = epochs if patience is None else patience\r\n",
        "    callbacks = [EarlyStoppingWithSigmasConvergence(patience=patience)]\r\n",
        "    # callbacks = [EarlyStopping(patience=patience)]\r\n",
        "    X_train.reset_index(inplace=True)\r\n",
        "    y_train.reset_index(inplace=True, drop=True)\r\n",
        "    X_train.sort_values(by=[RE_col], inplace=True)\r\n",
        "    y_train = y_train[X_train.index]\r\n",
        "    history = model.fit([X_train[x_cols], y_train, X_train[RE_col]], None,\r\n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.1,\r\n",
        "                        callbacks=callbacks, verbose=verbose)\r\n",
        "    \r\n",
        "    sig2e_est, sig2b_ests, _ = model.layers[-1].get_vars()\r\n",
        "    y_pred_tr = model.predict([X_train[x_cols], y_train, X_train[RE_col]]).reshape(X_train.shape[0])\r\n",
        "    y_pred_tr = np.clip(y_pred_tr, 1, 10)\r\n",
        "    b_hat = calc_b_hat(X_train[RE_col], y_train, y_pred_tr, n_cats, sig2e_est, sig2b_ests)\r\n",
        "    dummy_y_test = np.random.normal(size=y_test.shape)\r\n",
        "    y_pred = model.predict([X_test[x_cols], dummy_y_test, X_test[RE_col]]).reshape(X_test.shape[0]) + b_hat[X_test[RE_col]]\r\n",
        "    y_pred = np.clip(y_pred, 1, 10)\r\n",
        "    return y_pred, (sig2e_est, sig2b_ests), len(history.history['loss'])\r\n",
        "\r\n",
        "def reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False, verbose=False):\r\n",
        "    model = lstm_embed()\r\n",
        "\r\n",
        "    model.compile(loss='mse', optimizer='adam')\r\n",
        "\r\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\r\n",
        "    history = model.fit([X_train[x_cols], X_train[RE_col]], y_train,\r\n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.1,\r\n",
        "                        callbacks=callbacks, verbose=verbose)\r\n",
        "    y_pred = model.predict([X_test[x_cols], X_test[RE_col]]).reshape(X_test.shape[0])\r\n",
        "    y_pred = np.clip(y_pred, 1, 10)\r\n",
        "    return y_pred, (None, None), len(history.history['loss'])\r\n",
        "\r\n",
        "def reg_nn_menet(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False, verbose=False):\r\n",
        "    q = n_cats\r\n",
        "    clusters_train, clusters_test = X_train[RE_col].values, X_test[RE_col].values\r\n",
        "    X_train, X_test = X_train[x_cols].values, X_test[x_cols].values\r\n",
        "    y_train, y_test = y_train.values, y_test.values\r\n",
        "\r\n",
        "    model = lstm_ignore()\r\n",
        "    model.compile(loss='mse', optimizer='adam')\r\n",
        "\r\n",
        "    model, b_hat, sig2e_est, n_epochs, _ = menet_fit(model, X_train, y_train, clusters_train, q, batch_size, epochs, patience, verbose=verbose)\r\n",
        "    y_pred = menet_predict(model, X_test, clusters_test, q, b_hat)\r\n",
        "    y_pred = np.clip(y_pred, 1, 10)\r\n",
        "    return y_pred, (sig2e_est, None), n_epochs\r\n",
        "\r\n",
        "def reg_nn(X_train, X_test, y_train, y_test, n_cats, batch=30, epochs=100, patience=5, reg_type='ohe', deep=False, verbose=False):    \r\n",
        "    start = time.time()\r\n",
        "    if reg_type == 'ohe':\r\n",
        "        y_pred, sigmas, n_epochs = reg_nn_ohe(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep, verbose)\r\n",
        "    elif reg_type == 'lmm':\r\n",
        "        y_pred, sigmas, n_epochs = reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep, verbose)\r\n",
        "    elif reg_type == 'ignore':\r\n",
        "        y_pred, sigmas, n_epochs = reg_nn_ignore(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep, verbose)\r\n",
        "    elif reg_type == 'embed':\r\n",
        "        y_pred, sigmas, n_epochs = reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep, verbose)\r\n",
        "    elif reg_type == 'menet':\r\n",
        "        y_pred, sigmas, n_epochs = reg_nn_menet(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep, verbose)\r\n",
        "    else:\r\n",
        "        raise ValueError(reg_type + ' is an unknown reg_type')\r\n",
        "    end = time.time()\r\n",
        "    mse = np.mean((y_pred - y_test)**2)\r\n",
        "    return mse, sigmas, n_epochs, end - start"
      ],
      "outputs": [],
      "metadata": {
        "id": "i1vjzVMuWgZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "res = pd.DataFrame(columns=['experiment', 'exp_type', 'deep', 'mse', 'sigma_e_est', 'sigma_b_est', 'n_epochs', 'time'])\r\n",
        "counter = 0\r\n",
        "\r\n",
        "def iterate_reg_types(X_train, X_test, y_train, y_test, counter, deep=True, verbose=False):\r\n",
        "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='ignore', deep=deep, verbose=verbose)\r\n",
        "    print(' finished ignore deep=%s, mse: %.2f' % (deep, mse_ig))\r\n",
        "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='lmm', deep=deep, verbose=verbose)\r\n",
        "    print(' finished lmm deep=%s, mse: %.2f' % (deep, mse_lmm))\r\n",
        "    mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='ohe', deep=deep, verbose=verbose)\r\n",
        "    print(' finished ohe deep=%s, mse: %.2f' % (deep, mse_ohe))\r\n",
        "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='embed', deep=deep, verbose=verbose)\r\n",
        "    print(' finished embed deep=%s, mse: %.2f' % (deep, mse_em))\r\n",
        "    mse_me, sigmas_me, n_epochs_me, time_me = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='menet', deep=deep, verbose=verbose)\r\n",
        "    print(' finished menet deep=%s, mse: %.2f' % (deep, mse_me))\r\n",
        "    res.loc[next(counter)] = [i, 'ohe', deep, mse_ohe, np.nan, np.nan, n_epochs_ohe, time_ohe]\r\n",
        "    res.loc[next(counter)] = [i, 'lmm', deep, mse_lmm, sigmas[0], sigmas[1][0], n_epochs_lmm, time_lmm]\r\n",
        "    res.loc[next(counter)] = [i, 'ignore', deep, mse_ig, np.nan, np.nan, n_epochs_ig, time_ig]\r\n",
        "    res.loc[next(counter)] = [i, 'embed', deep, mse_em, np.nan, np.nan, n_epochs_em, time_em]\r\n",
        "    res.loc[next(counter)] = [i, 'menet', deep, mse_me, sigmas_me[0], np.nan, n_epochs_me, time_me]\r\n",
        "\r\n",
        "kf = KFold(n_splits=5)\r\n",
        "counter = Count().gen()\r\n",
        "y = drugs['rating']\r\n",
        "\r\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\r\n",
        "    print('iteration %d' % i)\r\n",
        "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\r\n",
        "    iterate_reg_types(X_train, X_test, y_train, y_test, counter, True, True)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l-LrfWXYWgZp",
        "outputId": "80aa6a65-7d16-4bb0-906a-fdb458d146f7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "res"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "FPSjULlZWgZp",
        "outputId": "a750ed18-05a8-4357-f2fb-99e24105f506"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "res.to_csv('../results/res_drugs.csv')"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}