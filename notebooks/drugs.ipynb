{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python387jvsc74a57bd0853417d72ad81a5e50a8613ae15c38dd8101027062a267a28f225259147f3710",
      "display_name": "Python 3.8.7 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Drugs_Ratings_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz7b58k2WgZg"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from lmmnn.layers import NLL\n",
        "from lmmnn.callbacks import EarlyStoppingWithSigmasConvergence\n",
        "from lmmnn.menet import menet_fit, menet_predict\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Reshape, Concatenate, Input, Layer, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_bWJVbwWgZg"
      },
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsV53IjcawCl"
      },
      "source": [
        "# The drugs_df CSV comes from simple binding the train and test TSVs from Gräßer et al. (2018),\n",
        "# available in the UCI ML repo, see our paper.\n",
        "drugs = pd.read_csv('drugs_df.csv')\n",
        "RE_col = 'drug_name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "3k-26fe-WgZh",
        "outputId": "7ae790f7-947b-4d13-ede7-02b982bf42b3"
      },
      "source": [
        "drugs.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>drug_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206461</td>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>9</td>\n",
              "      <td>May 20, 2012</td>\n",
              "      <td>27</td>\n",
              "      <td>3428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95260</td>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>8</td>\n",
              "      <td>April 27, 2010</td>\n",
              "      <td>192</td>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92703</td>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>5</td>\n",
              "      <td>December 14, 2009</td>\n",
              "      <td>17</td>\n",
              "      <td>1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>138000</td>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"This is my first time using any form of birth...</td>\n",
              "      <td>8</td>\n",
              "      <td>November 3, 2015</td>\n",
              "      <td>10</td>\n",
              "      <td>2456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35696</td>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Suboxone has completely turned my life around...</td>\n",
              "      <td>9</td>\n",
              "      <td>November 27, 2016</td>\n",
              "      <td>37</td>\n",
              "      <td>553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                  drugName  ... usefulCount drug_name\n",
              "0  206461                 Valsartan  ...          27      3428\n",
              "1   95260                Guanfacine  ...         192      1542\n",
              "2   92703                    Lybrel  ...          17      1989\n",
              "3  138000                Ortho Evra  ...          10      2456\n",
              "4   35696  Buprenorphine / naloxone  ...          37       553\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtxphUSvWgZj"
      },
      "source": [
        "max_features = 10000\n",
        "batch_size = 20\n",
        "epochs = 10\n",
        "seq_len = 100\n",
        "words_embed_dim = 100\n",
        "Z_embed_dim = 10\n",
        "lstm_kernels = 64\n",
        "n_cats = drugs[RE_col].max() + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqg-BtSgWgZj",
        "outputId": "5eb3e3e9-a980-4051-a3fd-118d00e6be3c"
      },
      "source": [
        "n_cats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3671"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2l6DPWWgZk",
        "outputId": "a024b5a3-b248-4127-ef47-8ab0996ea2ed"
      },
      "source": [
        "drugs[RE_col].min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn4vTU8cWgZk",
        "outputId": "ef020809-6d9e-405f-8e04-ddfd03bf452e"
      },
      "source": [
        "drugs[RE_col].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWNy52KjWgZk"
      },
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(drugs['review'])\n",
        "text_sequences = tokenizer.texts_to_sequences(drugs['review'])\n",
        "X = sequence.pad_sequences(text_sequences, padding='post', maxlen=seq_len)\n",
        "X = pd.DataFrame(X)\n",
        "x_cols = ['X' + str(i) for i in range(seq_len)]\n",
        "X.columns = x_cols\n",
        "X = pd.concat([X, drugs[RE_col]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8ftYpoyWgZk",
        "outputId": "35404164-c853-4dd5-95da-dbdd3ff15831"
      },
      "source": [
        "X.loc[0, x_cols].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   5,   38,   28,   35,  198,    1,   45,    5,   15,  832,   12,\n",
              "       2948,   99,  149,    2, 3852, 1585,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGLYZYXUWgZl",
        "outputId": "592c3e48-8c4b-41ac-e530-3925d6166302"
      },
      "source": [
        "((X[x_cols] > 0).astype(int).sum(axis=1) == seq_len).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.427009759930811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lJ4pVhZ1WgZl",
        "outputId": "4fcf6145-e9c1-4bac-8ec1-79a2390aedc4"
      },
      "source": [
        "drugs.loc[0, 'review']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRTKb4VWgZl",
        "outputId": "de37f9e5-7f09-4ca5-840d-de692da53f7b"
      },
      "source": [
        "tokenizer.word_index['it']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Q35JCiWgZl"
      },
      "source": [
        "def lstm_ignore():\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    output = Dense(1)(x)\n",
        "    return Model(inputs=[input_layer], outputs=output)\n",
        "\n",
        "def lstm_lmmnn():\n",
        "    input_layer = Input(shape=(seq_len, ), dtype=tf.int32)\n",
        "    y_true_input = Input(shape=(1, ),)\n",
        "    Z_input = Input(shape=(1, ), dtype=tf.int64)\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    y_pred_output = Dense(1)(x)\n",
        "    nll = NLL(1.0, 1.0)(y_true_input, y_pred_output, Z_input)\n",
        "    return Model(inputs=[input_layer, y_true_input, Z_input], outputs=nll)\n",
        "\n",
        "def lstm_embed():\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\n",
        "    Z_input = Input(shape=(1,))\n",
        "    embed = Embedding(n_cats, Z_embed_dim, input_length = 1)(Z_input)\n",
        "    embed = Reshape(target_shape = (Z_embed_dim, ))(embed)\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    concat = Concatenate()([x, embed])\n",
        "    output = Dense(1)(concat)\n",
        "    return Model(inputs=[input_layer, Z_input], outputs=output)\n",
        "\n",
        "def lstm_ohe(p):\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\n",
        "    ohe_input = Input(shape=(p, ))\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    concat = Concatenate()([x, ohe_input])\n",
        "    output = Dense(1)(concat)\n",
        "    return Model(inputs=[input_layer, ohe_input], outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaqoyIpBWgZm"
      },
      "source": [
        "def calc_b_hat(Z_train, y_train, y_pred_tr, n_cats, sig2e, sig2b):\n",
        "    b_hat = []\n",
        "    for i in range(n_cats):\n",
        "        i_vec = Z_train == i\n",
        "        n_i = i_vec.sum()\n",
        "        if n_i > 0:\n",
        "            y_bar_i = y_train[i_vec].mean()\n",
        "            y_pred_i = y_pred_tr[i_vec].mean()\n",
        "            # BP(b_i) = (n_i * sig2b / (sig2a + n_i * sig2b)) * (y_bar_i - y_pred_bar_i)\n",
        "            b_i = n_i * sig2b * (y_bar_i - y_pred_i) / (sig2e + n_i * sig2b)\n",
        "        else:\n",
        "            b_i = 0\n",
        "        b_hat.append(b_i)\n",
        "    return np.array(b_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPnvvceLWgZm"
      },
      "source": [
        "def process_one_hot_encoding(X_train, X_test, RE_col):\n",
        "    X_train_ohe = pd.concat([X_train[x_cols], pd.get_dummies(X_train[RE_col])], axis=1)\n",
        "    X_test_ohe = pd.concat([X_test[x_cols], pd.get_dummies(X_test[RE_col])], axis=1)\n",
        "    X_test_cols_in_train = set(X_test_ohe.columns).intersection(X_train_ohe.columns)\n",
        "    X_train_cols_not_in_test = set(X_train_ohe.columns).difference(X_test_ohe.columns)\n",
        "    X_test_comp = pd.DataFrame(np.zeros((X_test.shape[0], len(X_train_cols_not_in_test))),\n",
        "                               columns=X_train_cols_not_in_test, dtype=np.uint8, index=X_test.index)\n",
        "    X_test_ohe_comp = pd.concat([X_test_ohe[X_test_cols_in_train], X_test_comp], axis=1)\n",
        "    X_test_ohe_comp = X_test_ohe_comp[X_train_ohe.columns]\n",
        "    return X_train_ohe, X_test_ohe_comp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1vjzVMuWgZn"
      },
      "source": [
        "def reg_nn_ignore(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False):\n",
        "    model = lstm_ignore()\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
        "    history = model.fit(X_train[x_cols], y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        validation_split=0.1, callbacks=callbacks, verbose=1)\n",
        "    y_pred = model.predict(X_test[x_cols]).reshape(X_test.shape[0])\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (None, None), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_ohe(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False):\n",
        "    X_train, X_test = process_one_hot_encoding(X_train, X_test, RE_col)\n",
        "    model = lstm_ohe(X_train.drop(x_cols, axis=1).shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
        "    history = model.fit([X_train[x_cols], X_train.drop(x_cols, axis=1)], y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        validation_split=0.1, callbacks=callbacks, verbose=1)\n",
        "    y_pred = model.predict([X_test[x_cols], X_test.drop(x_cols, axis=1)]).reshape(X_test.shape[0])\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (None, None), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False):\n",
        "    model = lstm_lmmnn()\n",
        "    model.compile(optimizer= 'adam')\n",
        "    \n",
        "    patience = epochs if patience is None else patience\n",
        "    callbacks = [EarlyStoppingWithSigmasConvergence(patience=patience)]\n",
        "    # callbacks = [EarlyStopping(patience=patience)]\n",
        "    X_train.reset_index(inplace=True)\n",
        "    y_train.reset_index(inplace=True, drop=True)\n",
        "    X_train.sort_values(by=[RE_col], inplace=True)\n",
        "    y_train = y_train[X_train.index]\n",
        "    history = model.fit([X_train[x_cols], y_train, X_train[RE_col]], None,\n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.1,\n",
        "                        callbacks=callbacks, verbose=0)\n",
        "    \n",
        "    sig2e_est, sig2b_est = model.layers[-1].get_vars()\n",
        "    y_pred_tr = model.predict([X_train[x_cols], y_train, X_train[RE_col]]).reshape(X_train.shape[0])\n",
        "    y_pred_tr = np.clip(y_pred_tr, 1, 10)\n",
        "    b_hat = calc_b_hat(X_train[RE_col], y_train, y_pred_tr, n_cats, sig2e_est, sig2b_est)\n",
        "    dummy_y_test = np.random.normal(size=y_test.shape)\n",
        "    y_pred = model.predict([X_test[x_cols], dummy_y_test, X_test[RE_col]]).reshape(X_test.shape[0]) + b_hat[X_test[RE_col]]\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (sig2e_est, sig2b_est), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False):\n",
        "    model = lstm_embed()\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
        "    history = model.fit([X_train[x_cols], X_train[RE_col]], y_train,\n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.1,\n",
        "                        callbacks=callbacks, verbose=1)\n",
        "    y_pred = model.predict([X_test[x_cols], X_test[RE_col]]).reshape(X_test.shape[0])\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (None, None), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_menet(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, deep=False):\n",
        "    q = n_cats\n",
        "    clusters_train, clusters_test = X_train[RE_col].values, X_test[RE_col].values\n",
        "    X_train, X_test = X_train[x_cols].values, X_test[x_cols].values\n",
        "    y_train, y_test = y_train.values, y_test.values\n",
        "\n",
        "    model = lstm_ignore()\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    model, b_hat, sig2e_est, n_epochs, _ = menet_fit(model, X_train, y_train, clusters_train, q, batch_size, epochs, patience, verbose=True)\n",
        "    y_pred = menet_predict(model, X_test, clusters_test, q, b_hat)\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (sig2e_est, None), n_epochs\n",
        "\n",
        "def reg_nn(X_train, X_test, y_train, y_test, n_cats, batch=30, epochs=100, patience=5, reg_type='ohe', deep=False):    \n",
        "    start = time.time()\n",
        "    if reg_type == 'ohe':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_ohe(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep)\n",
        "    elif reg_type == 'lmm':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep)\n",
        "    elif reg_type == 'ignore':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_ignore(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep)\n",
        "    elif reg_type == 'embed':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep)\n",
        "    elif reg_type == 'menet':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_menet(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, deep)\n",
        "    else:\n",
        "        raise ValueError(reg_type + ' is an unknown reg_type')\n",
        "    end = time.time()\n",
        "    mse = np.mean((y_pred - y_test)**2)\n",
        "    return mse, sigmas, n_epochs, end - start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l-LrfWXYWgZp",
        "outputId": "80aa6a65-7d16-4bb0-906a-fdb458d146f7"
      },
      "source": [
        "res = pd.DataFrame(columns=['experiment', 'exp_type', 'deep', 'mse', 'sigma_e_est', 'sigma_b_est', 'n_epochs', 'time'])\n",
        "counter = 0\n",
        "\n",
        "def iterate_reg_types(X_train, X_test, y_train, y_test, deep=True):\n",
        "    global counter\n",
        "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='ignore', deep=deep)\n",
        "    print(' finished ignore deep=%s, mse: %.2f' % (deep, mse_ig))\n",
        "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='lmm', deep=deep)\n",
        "    print(' finished lmm deep=%s, mse: %.2f' % (deep, mse_lmm))\n",
        "    mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='ohe', deep=deep)\n",
        "    print(' finished ohe deep=%s, mse: %.2f' % (deep, mse_ohe))\n",
        "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='embed', deep=deep)\n",
        "    print(' finished embed deep=%s, mse: %.2f' % (deep, mse_em))\n",
        "    mse_me, sigmas_me, n_epochs_me, time_me = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='menet', deep=deep)\n",
        "    print(' finished menet deep=%s, mse: %.2f' % (deep, mse_me))\n",
        "    mse_dec = 100 * (mse_lmm - mse_lm) / mse_lm\n",
        "    res.loc[counter + 0] = [i, 'ohe', deep, mse_ohe, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
        "    res.loc[counter + 1] = [i, 'lmm', deep, mse_lmm, sigmas[0], sigmas[1], n_epochs_lmm, time_lmm]\n",
        "    res.loc[counter + 2] = [i, 'ignore', deep, mse_ig, np.nan, np.nan, n_epochs_ig, time_ig]\n",
        "    res.loc[counter + 3] = [i, 'embed', deep, mse_em, np.nan, np.nan, n_epochs_em, time_em]\n",
        "    res.loc[counter + 4] = [i, 'menet', deep, mse_me, sigmas_me[0], np.nan, n_epochs_me, time_me]\n",
        "    counter += 5\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "y = drugs['rating']\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "    print('iteration %d' % i)\n",
        "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
        "    iterate_reg_types(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "FPSjULlZWgZp",
        "outputId": "a750ed18-05a8-4357-f2fb-99e24105f506"
      },
      "source": [
        "res"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res.to_csv('../results/res_drugs.csv')"
      ]
    }
  ]
}