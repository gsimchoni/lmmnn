{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmnn.nn import reg_nn_ohe_or_ignore, reg_nn_lmm, reg_nn_embed, reg_nn_rnn\n",
    "from lmmnn.simulation import Count\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AU anual commodities import data from Kaggle (by UN): https://www.kaggle.com/datasets/unitednations/global-commodity-trade-statistics\n",
    "# Run au_import_etl.R script\n",
    "au_import = pd.read_csv('../../au_anual_import_commodity.csv')\n",
    "cols_to_drop = ['commodity', 'year', 'comm_code']\n",
    "au_import.drop(cols_to_drop, axis=1, inplace=True)\n",
    "print(au_import.shape)\n",
    "au_import.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_import['trade_usd'] = np.log(au_import['trade_usd'])\n",
    "au_import['trade_usd'].plot(kind='hist', bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(au_import['commodity_id'].unique()))\n",
    "print(au_import['commodity_id'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_import.rename(columns={'commodity_id': 'z0', 'trade_usd': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'slopes'\n",
    "batch_size = 100\n",
    "epochs = 500\n",
    "patience = 10\n",
    "n_sig2bs = 3\n",
    "est_cors = []\n",
    "n_neurons = [100, 50, 25, 12]\n",
    "activation = 'relu'\n",
    "dropout = [0.25, 0.25, 0.25]\n",
    "spatial_embedded_neurons = []\n",
    "dist_matrix = None\n",
    "q_spatial = None\n",
    "n_sig2bs_spatial = 0\n",
    "n_cats = [len(au_import['z0'].unique())]\n",
    "time2measure_dict = {t: i for i, t in enumerate(np.sort(au_import['t'].unique()))} # for RNN\n",
    "pred_future = False # change this for future mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn(X_train, X_test, y_train, y_test, n_cats, batch=batch_size, epochs=epochs, patience=patience, reg_type='ohe', verbose=False):\n",
    "    start = time.time()\n",
    "    if reg_type == 'ohe':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(X_train, X_test, y_train, y_test, n_cats, x_cols, batch, epochs, patience,\n",
    "                                                           n_neurons, dropout, activation,\n",
    "                                                           mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'lmm':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, q_spatial, x_cols, batch, epochs, patience,\n",
    "                                                 n_neurons, dropout, activation,\n",
    "                                                 mode=mode, n_sig2bs=n_sig2bs, n_sig2bs_spatial=n_sig2bs_spatial,\n",
    "                                                 est_cors=est_cors, dist_matrix=dist_matrix,\n",
    "                                                 spatial_embed_neurons=spatial_embedded_neurons, verbose=verbose, log_params=False)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(X_train, X_test, y_train, y_test, n_cats, x_cols, batch, epochs, patience,\n",
    "                                                           n_neurons, dropout, activation,\n",
    "                                                           mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose, ignore_RE=True)\n",
    "    elif reg_type == 'embed':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, q_spatial, x_cols, batch, epochs, patience,\n",
    "                                                   n_neurons, dropout, activation,\n",
    "                                                   mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'rnn':\n",
    "        rnn_res, sigmas, _, _, n_epochs = reg_nn_rnn(X_train, X_test, y_train, y_test, n_cats, x_cols, batch, epochs,\n",
    "                                            patience, n_neurons, dropout, activation, mode, time2measure_dict,\n",
    "                                            n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    else:\n",
    "      raise ValueError(reg_type + 'is an unknown reg_type')\n",
    "    end = time.time()\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    if reg_type == 'rnn': # RNN computes MSE inside function currently\n",
    "      mse = rnn_res\n",
    "    else:\n",
    "      mse = np.mean((y_pred - y_test)**2)\n",
    "      plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "      plt.show()\n",
    "    return mse, sigmas, n_epochs, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est',\n",
    "                            'sigma_b0_est', 'sigma_b1_est', 'sigma_b2_est',\n",
    "                            'n_epoch', 'time'])\n",
    "counter = Count().gen()\n",
    "\n",
    "def iterate_reg_types(X_train, X_test, y_train, y_test, verbose):\n",
    "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='lmm', verbose=verbose)\n",
    "    print(' finished lmm, mse: %.2f' % (mse_lmm))\n",
    "    mse_rnn, _, n_epochs_rnn, time_rnn = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='rnn', verbose=verbose)\n",
    "    print(' finished rnn, mse: %.2f' % (mse_rnn))\n",
    "    mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='ohe', verbose=verbose)\n",
    "    print(' finished ohe, mse: %.2f' % (mse_ohe))\n",
    "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='ignore', verbose=verbose)\n",
    "    print(' finished ignore, mse: %.2f' % (mse_ig))\n",
    "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, n_cats, reg_type='embed', verbose=verbose)\n",
    "    print(' finished embed, mse: %.2f' % (mse_em))\n",
    "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[1][0], sigmas[1][1], sigmas[1][2],\n",
    "                              n_epochs_lmm, time_lmm]\n",
    "    res.loc[next(counter)] = [i, 'rnn', mse_rnn, np.nan, np.nan, np.nan, np.nan, n_epochs_rnn, time_rnn]\n",
    "    res.loc[next(counter)] = [i, 'ohe', mse_ohe, np.nan, np.nan, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
    "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, np.nan, np.nan, n_epochs_ig, time_ig]\n",
    "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, np.nan, np.nan, n_epochs_em, time_em]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "if pred_future:\n",
    "  # test set is \"the future\" or those obs with largest t\n",
    "  au_import.sort_values('t', inplace=True)\n",
    "  X, X_future, y, y_future = train_test_split(\n",
    "      au_import.drop('y', axis=1), au_import['y'], test_size=0.2, shuffle=False)\n",
    "  X.index = np.arange(X.shape[0])\n",
    "  y.index = np.arange(X.shape[0])\n",
    "else:\n",
    "  X, y = au_import.drop('y', axis=1), au_import['y']\n",
    "\n",
    "x_cols = [col for col in X.columns if col not in ['z0']]\n",
    "x_cols_to_scale = [col for col in x_cols if col not in ['t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    if not pred_future:\n",
    "      X_train, X_test, y_train, y_test = X.loc[train_index].copy(), X.loc[test_index].copy(), y[train_index], y[test_index]\n",
    "    else:\n",
    "      X_train, X_test, y_train, y_test = X.loc[train_index].copy(), X_future.copy(), y[train_index], y_future.copy()\n",
    "    scaler = StandardScaler()\n",
    "    X_train[x_cols_to_scale] = scaler.fit_transform(X_train[x_cols_to_scale])\n",
    "    X_test[x_cols_to_scale] = scaler.transform(X_test[x_cols_to_scale])\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_future:\n",
    "    res_file = '../../results/res_au_import_future.csv'\n",
    "else:\n",
    "    res_file = '../../results/res_au_import_random.csv'\n",
    "res.to_csv(res_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
