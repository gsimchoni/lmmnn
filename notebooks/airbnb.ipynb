{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd0853417d72ad81a5e50a8613ae15c38dd8101027062a267a28f225259147f3710",
   "display_name": "Python 3.8.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmnn.layers import NLL\n",
    "from lmmnn.callbacks import EarlyStoppingWithSigmasConvergence\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Layer, Input, Dropout, Embedding, Reshape, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: data_cleaned_train_comments_X.csv is the result of an ETL process described in Kalehbasti et. al. (2019), see our paper.\n",
    "# We followed the script in their Github repo exactly.\n",
    "path = 'C:/Users/gsimchoni/AirBnbPricePrediction/Data/'\n",
    "X_train = pd.read_csv(path + 'data_cleaned_train_comments_X.csv')\n",
    "y_train = pd.read_csv(path + 'data_cleaned_train_y.csv').values\n",
    "y_train = y_train.reshape(len(y_train), )\n",
    "\n",
    "X_val = pd.read_csv(path + 'data_cleaned_val_comments_X.csv')\n",
    "y_val = pd.read_csv(path + 'data_cleaned_val_y.csv').values\n",
    "y_val = y_val.reshape(len(y_val), )\n",
    "\n",
    "X_test = pd.read_csv(path + 'data_cleaned_test_comments_X.csv')\n",
    "y_test = pd.read_csv(path + 'data_cleaned_test_y.csv').values\n",
    "y_test = y_test.reshape(len(y_test), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.load(path + 'selected_coefs.npy')\n",
    "col_set = set()\n",
    "\n",
    "for i in range(len(coeffs)):\n",
    "        if (coeffs[i]):\n",
    "            col_set.add(X_train.columns[i])\n",
    "X_train = X_train[list(col_set | set(['host_id']))]\n",
    "X_val = X_val[list(col_set | set(['host_id']))]\n",
    "X_test = X_test[list(col_set | set(['host_id']))]\n",
    "\n",
    "X = pd.concat([X_train, X_val, X_test], ignore_index=True)\n",
    "y = np.concatenate([y_train, y_val, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(49976, 197)\n(49976,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant Adam params taken from original paper\n",
    "NUM_ITERATIONS = 1000\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DECAY_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cats = max([X_train['host_id'].max(), X_val['host_id'].max(), X_test['host_id'].max()]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(col_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'24-hour_check-in',\n",
       " 'Accessible-height_bed',\n",
       " 'Accessible-height_toilet',\n",
       " 'Air_conditioning',\n",
       " 'Apartment',\n",
       " 'Arverne.1',\n",
       " 'Astoria.1',\n",
       " 'Baby_bath',\n",
       " 'Babysitter_recommendations',\n",
       " 'Bathtub',\n",
       " 'Bay Ridge',\n",
       " 'Bed_linens',\n",
       " 'Bensonhurst',\n",
       " 'Boerum Hill',\n",
       " 'Borough Park',\n",
       " 'Boutique hotel',\n",
       " 'Breakfast',\n",
       " 'Bronx',\n",
       " 'Bronx.1',\n",
       " 'Brooklyn ',\n",
       " 'Brooklyn Heights',\n",
       " 'Brooklyn.1',\n",
       " 'Bushwick.1',\n",
       " 'Buzzer/wireless_intercom',\n",
       " 'Cable_TV',\n",
       " 'Carbon_monoxide_detector',\n",
       " 'Carroll Gardens',\n",
       " 'Cat(s)',\n",
       " 'Chelsea',\n",
       " 'Children’s_books_and_toys',\n",
       " 'Clinton Hill',\n",
       " 'Cobble Hill',\n",
       " 'Coffee_maker',\n",
       " 'Cooking_basics',\n",
       " 'Crib',\n",
       " 'Cypress Hills',\n",
       " 'DUMBO',\n",
       " 'Dishes_and_silverware',\n",
       " 'Dishwasher',\n",
       " 'Doorman',\n",
       " 'Downtown Brooklyn',\n",
       " 'Dryer',\n",
       " 'East Flatbush',\n",
       " 'East Harlem',\n",
       " 'East Village',\n",
       " 'Elevator',\n",
       " 'Elmhurst.1',\n",
       " 'Entire home/apt',\n",
       " 'Essentials',\n",
       " 'Ethernet_connection',\n",
       " 'Extra_pillows_and_blankets',\n",
       " 'Family/kid_friendly',\n",
       " 'Financial District',\n",
       " 'Fire_extinguisher',\n",
       " 'First_aid_kit',\n",
       " 'Flat_path_to_front_door',\n",
       " 'Flatbush',\n",
       " 'Flatiron District',\n",
       " 'Forest Hills.1',\n",
       " 'Fort Greene',\n",
       " 'Free_parking_on_premises',\n",
       " 'Free_street_parking',\n",
       " 'Game_console',\n",
       " 'Garden_or_backyard',\n",
       " 'Gowanus',\n",
       " 'Gramercy',\n",
       " 'Gravesend',\n",
       " 'Greenpoint',\n",
       " 'Greenwich Village',\n",
       " 'Guest suite',\n",
       " 'Gym',\n",
       " 'Hair_dryer',\n",
       " 'Handheld_shower_head',\n",
       " 'Hangers',\n",
       " 'Harlem.1',\n",
       " 'Heating',\n",
       " \"Hell's Kitchen\",\n",
       " 'High_chair',\n",
       " 'Host_greets_you',\n",
       " 'Hot_tub',\n",
       " 'Hot_water',\n",
       " 'Hotel',\n",
       " 'House',\n",
       " 'Indoor_fireplace',\n",
       " 'Internet',\n",
       " 'Inwood',\n",
       " 'Iron',\n",
       " 'Kensington',\n",
       " 'Keypad',\n",
       " 'Kitchen',\n",
       " 'Laptop_friendly_workspace',\n",
       " 'Little Italy',\n",
       " 'Lock_on_bedroom_door',\n",
       " 'Lockbox',\n",
       " 'Loft',\n",
       " 'Long Island City.1',\n",
       " 'Long_term_stays_allowed',\n",
       " 'Lower East Side',\n",
       " 'Luggage_dropoff_allowed',\n",
       " 'Manhattan',\n",
       " 'Microwave',\n",
       " 'Midtown',\n",
       " 'Midwood',\n",
       " 'Morningside Heights',\n",
       " 'NoHo',\n",
       " 'Nolita',\n",
       " 'Other',\n",
       " 'Oven',\n",
       " 'Pack_’n_Play/travel_crib',\n",
       " 'Paid_parking_off_premises',\n",
       " 'Paid_parking_on_premises',\n",
       " 'Park Slope',\n",
       " 'Patio_or_balcony',\n",
       " 'Pets_allowed',\n",
       " 'Pets_live_on_this_property',\n",
       " 'Pocket_wifi',\n",
       " 'Pool',\n",
       " 'Private_entrance',\n",
       " 'Private_living_room',\n",
       " 'Prospect Heights',\n",
       " 'Prospect-Lefferts Gardens',\n",
       " 'Queens',\n",
       " 'Queens.1',\n",
       " 'Real Bed',\n",
       " 'Refrigerator',\n",
       " 'Rego Park.1',\n",
       " 'Resort',\n",
       " 'Ridgewood.1',\n",
       " 'Riverdale',\n",
       " 'Rockaway Beach.1',\n",
       " 'Room-darkening_shades',\n",
       " 'Roosevelt Island',\n",
       " 'Safety_card',\n",
       " 'Self_check-in',\n",
       " 'Serviced apartment',\n",
       " 'Shampoo',\n",
       " 'Shared room',\n",
       " 'Smart_lock',\n",
       " 'Smoke_detector',\n",
       " 'Smoking_allowed',\n",
       " 'SoHo',\n",
       " 'South Slope',\n",
       " 'Springfield Gardens.1',\n",
       " 'Stair_gates',\n",
       " 'Staten Island',\n",
       " 'Staten Island.1',\n",
       " 'Stove',\n",
       " 'Suitable_for_events',\n",
       " 'Sunset Park',\n",
       " 'TV',\n",
       " 'Theater District',\n",
       " 'Townhouse',\n",
       " 'Tribeca',\n",
       " 'Upper West Side',\n",
       " 'Wakefield',\n",
       " 'Washer',\n",
       " 'Washington Heights',\n",
       " 'Well-lit_path_to_entrance',\n",
       " 'West Village',\n",
       " 'Wheelchair_accessible',\n",
       " 'Wifi',\n",
       " 'Williamsburg.1',\n",
       " 'Window_guards',\n",
       " 'Woodhaven.1',\n",
       " 'Woodside.1',\n",
       " 'a few days or more',\n",
       " 'accommodates',\n",
       " 'bedrooms',\n",
       " 'cleaning_fee',\n",
       " 'extra_people',\n",
       " 'facebook_verification',\n",
       " 'flexible',\n",
       " 'google_verification',\n",
       " 'government_id_verification',\n",
       " 'guests_included',\n",
       " 'host_has_profile_pic',\n",
       " 'host_is_superhost',\n",
       " 'host_since',\n",
       " 'identity_manual_verification',\n",
       " 'instant_bookable',\n",
       " 'longitude',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_value',\n",
       " 'reviews_per_month',\n",
       " 'reviews_verification',\n",
       " 'security_deposit',\n",
       " 'strict_14_with_grace_period',\n",
       " 'within a day',\n",
       " 'within a few hours',\n",
       " 'within an hour',\n",
       " 'work_email_verification'}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "col_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_b_hat(X_train, y_train, y_pred_tr, n_cats, sig2e, sig2b, Z_name):\n",
    "    b_hat = []\n",
    "    for i in range(n_cats):\n",
    "        i_vec = X_train[Z_name] == i\n",
    "        n_i = i_vec.sum()\n",
    "        if n_i > 0:\n",
    "            y_bar_i = y_train[i_vec].mean()\n",
    "            y_pred_i = y_pred_tr[i_vec].mean()\n",
    "            # BP(b_i) = (n_i * sig2b / (sig2a + n_i * sig2b)) * (y_bar_i - y_pred_bar_i)\n",
    "            b_i = n_i * sig2b * (y_bar_i - y_pred_i) / (sig2e + n_i * sig2b)\n",
    "        else:\n",
    "            b_i = 0\n",
    "        b_hat.append(b_i)\n",
    "    return np.array(b_hat)\n",
    "\n",
    "def process_one_hot_encoding(X_train, X_test, RE_col):\n",
    "    X_train_ohe = pd.concat([X_train[x_cols], pd.get_dummies(X_train[RE_col])], axis=1)\n",
    "    X_test_ohe = pd.concat([X_test[x_cols], pd.get_dummies(X_test[RE_col])], axis=1)\n",
    "    X_test_cols_in_train = set(X_test_ohe.columns).intersection(X_train_ohe.columns)\n",
    "    X_train_cols_not_in_test = set(X_train_ohe.columns).difference(X_test_ohe.columns)\n",
    "    X_test_comp = pd.DataFrame(np.zeros((X_test.shape[0], len(X_train_cols_not_in_test))),\n",
    "                               columns=X_train_cols_not_in_test, dtype=np.uint8, index=X_test.index)\n",
    "    X_test_ohe_comp = pd.concat([X_test_ohe[X_test_cols_in_train], X_test_comp], axis=1)\n",
    "    X_test_ohe_comp = X_test_ohe_comp[X_train_ohe.columns]\n",
    "    return X_train_ohe, X_test_ohe_comp\n",
    "\n",
    "def reg_nn(X_train, X_test, y_train, y_test, batch=30, epochs=500, patience=10, reg_type='lm'):    \n",
    "#     if reg_type == 'lm':\n",
    "#         pass#y_pred, sigmas = reg_nn_lm(X_train, X_test, y_train, y_test, batch, epochs, patience, deep)\n",
    "    if reg_type == 'lmm':\n",
    "        y_pred, sigmas = reg_nn_lmm(X_train, X_test, y_train, y_test, batch, epochs, patience)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas = reg_nn_ignore(X_train, X_test, y_train, y_test, batch, epochs, patience)\n",
    "    else:\n",
    "        y_pred, sigmas = reg_nn_embed(X_train, X_test, y_train, y_test, batch, epochs, patience)\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    return mse, sigmas\n",
    "\n",
    "def reg_nn_ignore(X_train, X_test, y_train, y_test, batch_size, epochs, patience):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units=20, activation='relu', input_dim=len(X_train[col_set].values[0])))\n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "    history = model.fit(X_train[col_set], y_train, epochs=NUM_ITERATIONS, verbose=0,\n",
    "                        batch_size=BATCH_SIZE, validation_split = 0.1, callbacks=callbacks)\n",
    "    y_pred = model.predict(X_test[col_set]).reshape(X_test.shape[0])\n",
    "    return y_pred, (None, None)\n",
    "\n",
    "def reg_nn_embed(X_train, X_test, y_train, y_test, batch_size, epochs, patience):\n",
    "    embed_dim = 100\n",
    "\n",
    "    X_input = Input(shape=(X_train[col_set].shape[1],))\n",
    "    Z_input = Input(shape=(1,))\n",
    "    embed = Embedding(n_cats, embed_dim, input_length = 1)(Z_input)\n",
    "    embed = Reshape(target_shape = (embed_dim,))(embed)\n",
    "    concat = Concatenate()([X_input, embed])\n",
    "    \n",
    "    hidden1 = Dense(units=20, activation='relu', input_dim=len(X_train[col_set].values[0]))(concat)\n",
    "    hidden2 = Dense(units=5, activation='relu')(hidden1)\n",
    "    output = Dense(1, activation='linear')(hidden2)\n",
    "\n",
    "    model = Model(inputs=[X_input, Z_input], outputs=output)\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
    "    history = model.fit([X_train[col_set], X_train['host_id']], y_train, batch_size=batch_size, epochs=epochs,\n",
    "                        validation_split=0.1, callbacks=callbacks, verbose=0)\n",
    "    y_pred = model.predict([X_test[col_set], X_test['host_id']]).reshape(X_test.shape[0])\n",
    "    return y_pred, (None, None)\n",
    "\n",
    "def reg_nn_lmm(X_train, X_test, y_train, y_test, batch_size, epochs, patience):\n",
    "    X_input = Input(shape=(X_train[col_set].shape[1],))\n",
    "    y_true_input = Input(shape=(1,))\n",
    "    Z_input = Input(shape=(1,), dtype=tf.int64)\n",
    "    hidden1 = Dense(units=20, activation='relu', input_dim=len(X_train[col_set].values[0]))(X_input)\n",
    "    hidden2 = Dense(units=5, activation='relu')(hidden1)\n",
    "    y_pred_output = Dense(1, activation='linear')(hidden2)\n",
    "    nll = NLL(1.0, 1.0)(y_true_input, y_pred_output, Z_input)\n",
    "    model = Model(inputs=[X_input, y_true_input, Z_input], outputs=nll)\n",
    "\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(optimizer= adam)\n",
    "\n",
    "    callbacks = [EarlyStoppingWithSigmasConvergence(patience = 10)]\n",
    "    history = model.fit([X_train[col_set], y_train, X_train['host_id']], None, batch_size=batch_size, epochs=epochs,\n",
    "                        validation_split=0.1, callbacks=callbacks, verbose=0)\n",
    "\n",
    "    sig2e_est, sig2b_est = model.layers[-1].get_vars()\n",
    "    y_pred_tr = model.predict([X_train[col_set], y_train, X_train['host_id']]).reshape(X_train.shape[0])\n",
    "    b_hat = calc_b_hat(X_train, y_train, y_pred_tr, n_cats, sig2e_est, sig2b_est, 'host_id')\n",
    "    y_pred = model.predict([X_test[col_set], np.random.normal(size=y_test.shape), X_test['host_id']]).reshape(X_test.shape[0]) + b_hat[X_test['host_id']]\n",
    "    return y_pred, (sig2e_est, sig2b_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 0\n",
      " finished lmm deep=True, mse: 0.14\n",
      " finished ignore deep=True, mse: 0.15\n",
      " finished embed deep=True, mse: 0.15\n",
      "iteration 1\n",
      " finished lmm deep=True, mse: 0.14\n",
      " finished ignore deep=True, mse: 0.16\n",
      " finished embed deep=True, mse: 0.16\n",
      "iteration 2\n",
      " finished lmm deep=True, mse: 0.14\n",
      " finished ignore deep=True, mse: 0.15\n",
      " finished embed deep=True, mse: 0.16\n",
      "iteration 3\n",
      " finished lmm deep=True, mse: 0.14\n",
      " finished ignore deep=True, mse: 0.15\n",
      " finished embed deep=True, mse: 0.15\n",
      "iteration 4\n",
      " finished lmm deep=True, mse: 0.15\n",
      " finished ignore deep=True, mse: 0.16\n",
      " finished embed deep=True, mse: 0.16\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'deep', 'mse', 'sigma_e_est', 'sigma_b_est'])\n",
    "counter = 0\n",
    "\n",
    "def iterate_reg_types(X_train, X_test, y_train, y_test, deep):\n",
    "    global counter\n",
    "    mse_lmm, sigmas = reg_nn(X_train, X_test, y_train, y_test, reg_type='lmm')\n",
    "    print(' finished lmm deep=%s, mse: %.2f' % (deep, mse_lmm))\n",
    "    mse_ig, _ = reg_nn(X_train, X_test, y_train, y_test, reg_type='ignore')\n",
    "    print(' finished ignore deep=%s, mse: %.2f' % (deep, mse_ig))\n",
    "    mse_em, _ = reg_nn(X_train, X_test, y_train, y_test, reg_type='embed')\n",
    "    print(' finished embed deep=%s, mse: %.2f' % (deep, mse_em))\n",
    "    res.loc[counter + 0] = [i, 'lmm', deep, mse_lmm, sigmas[0], sigmas[1]]\n",
    "    res.loc[counter + 1] = [i, 'ignore', deep, mse_ig, np.nan, np.nan]\n",
    "    res.loc[counter + 2] = [i, 'embed', deep, mse_em, np.nan, np.nan]\n",
    "    counter += 3\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   experiment exp_type  deep       mse  sigma_e_est  sigma_b_est\n",
       "0           0      lmm  True  0.139199     0.066692     0.077929\n",
       "1           0   ignore  True  0.150673          NaN          NaN\n",
       "2           0    embed  True  0.150674          NaN          NaN\n",
       "3           1      lmm  True  0.144429     0.061695     0.072743\n",
       "4           1   ignore  True  0.161680          NaN          NaN\n",
       "5           1    embed  True  0.163593          NaN          NaN\n",
       "6           2      lmm  True  0.140581     0.062678     0.070015\n",
       "7           2   ignore  True  0.152785          NaN          NaN\n",
       "8           2    embed  True  0.158924          NaN          NaN\n",
       "9           3      lmm  True  0.140788     0.062919     0.070368\n",
       "10          3   ignore  True  0.152616          NaN          NaN\n",
       "11          3    embed  True  0.154781          NaN          NaN\n",
       "12          4      lmm  True  0.149100     0.065086     0.073124\n",
       "13          4   ignore  True  0.160530          NaN          NaN\n",
       "14          4    embed  True  0.164070          NaN          NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experiment</th>\n      <th>exp_type</th>\n      <th>deep</th>\n      <th>mse</th>\n      <th>sigma_e_est</th>\n      <th>sigma_b_est</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>lmm</td>\n      <td>True</td>\n      <td>0.139199</td>\n      <td>0.066692</td>\n      <td>0.077929</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>ignore</td>\n      <td>True</td>\n      <td>0.150673</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>embed</td>\n      <td>True</td>\n      <td>0.150674</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>lmm</td>\n      <td>True</td>\n      <td>0.144429</td>\n      <td>0.061695</td>\n      <td>0.072743</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>ignore</td>\n      <td>True</td>\n      <td>0.161680</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>embed</td>\n      <td>True</td>\n      <td>0.163593</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>lmm</td>\n      <td>True</td>\n      <td>0.140581</td>\n      <td>0.062678</td>\n      <td>0.070015</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>ignore</td>\n      <td>True</td>\n      <td>0.152785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>embed</td>\n      <td>True</td>\n      <td>0.158924</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>lmm</td>\n      <td>True</td>\n      <td>0.140788</td>\n      <td>0.062919</td>\n      <td>0.070368</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>ignore</td>\n      <td>True</td>\n      <td>0.152616</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>embed</td>\n      <td>True</td>\n      <td>0.154781</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4</td>\n      <td>lmm</td>\n      <td>True</td>\n      <td>0.149100</td>\n      <td>0.065086</td>\n      <td>0.073124</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>ignore</td>\n      <td>True</td>\n      <td>0.160530</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4</td>\n      <td>embed</td>\n      <td>True</td>\n      <td>0.164070</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../results/res_airbnb.csv')"
   ]
  }
 ]
}