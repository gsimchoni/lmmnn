{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmnn.nn import reg_nn_ohe_or_ignore, reg_nn_embed, reg_nn_lmm\n",
    "from lmmnn.simulation import Count\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The spotify songs dataset from Tidy Tuesday: https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-01-21\n",
    "# Run spotify_etl.R script\n",
    "spotify = pd.read_csv('../../data/spotify_df.csv')\n",
    "cols_to_drop = ['track_id', 'track_artist', 'track_album_id', 'track_album_release_date', 'pl_subgenres', 'playlist_ids']\n",
    "spotify.drop(cols_to_drop, axis=1, inplace=True)\n",
    "print(spotify.shape)\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify['danceability'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spotify['album_id'].unique()))\n",
    "print(spotify['album_id'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cats_artist = len(spotify['artist_id'].unique())\n",
    "n_cats_album = len(spotify['album_id'].unique())\n",
    "n_cats_playlist = len(spotify['playlist_id'].unique())\n",
    "n_cats_subgenre = len(spotify['subgenre_id'].unique())\n",
    "print(f'no. of artists: {n_cats_artist}')\n",
    "print(f'no. of albums: {n_cats_album}')\n",
    "print(f'no. of playlists: {n_cats_playlist}')\n",
    "print(f'no. of subgenres: {n_cats_subgenre}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.rename(columns={'artist_id': 'z0',\n",
    "                        'album_id': 'z1',\n",
    "                        'playlist_id': 'z2',\n",
    "                        'subgenre_id': 'z3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "epochs = 100\n",
    "patience = 10\n",
    "mode = 'intercepts'\n",
    "n_sig2bs = 4\n",
    "est_cors = []\n",
    "n_neurons = [10, 3]\n",
    "activation = 'relu'\n",
    "dropout = []\n",
    "spatial_embedded_neurons = []\n",
    "qs = [n_cats_artist, n_cats_album, n_cats_playlist, n_cats_subgenre]\n",
    "dist_matrix = None\n",
    "q_spatial = None\n",
    "Z_non_linear = False\n",
    "Z_embed_dim_pct = 10\n",
    "n_sig2bs_spatial = 0\n",
    "time2measure_dict = None\n",
    "spatial_embed_neurons = None\n",
    "resultion = None\n",
    "verbose = True\n",
    "log_params = False\n",
    "idx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn(X_train, X_test, y_train, y_test, reg_type):\n",
    "    start = time.time()\n",
    "    if reg_type == 'ohe':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'lmm':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_lmm(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, dist_matrix, spatial_embed_neurons, verbose, Z_non_linear, Z_embed_dim_pct, log_params, idx)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose, ignore_RE=True)\n",
    "    elif reg_type == 'embed':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_embed(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    else:\n",
    "        raise ValueError(reg_type + 'is an unknown reg_type')\n",
    "    end = time.time()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    y_pred = np.clip(y_pred, 0, 1)\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.show()\n",
    "    return mse, sigmas, n_epochs, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est',\n",
    "                            'sigma_b0_est', 'sigma_b1_est', 'sigma_b2_est', 'sigma_b3_est',\n",
    "                            'n_epoch', 'time'])\n",
    "counter = Count().gen()\n",
    "\n",
    "def iterate_reg_types(X_train, X_test, y_train, y_test):\n",
    "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, reg_type='lmm')\n",
    "    print(' finished lmm, mse: %.4f' % (mse_lmm))\n",
    "    # mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, reg_type='ohe')\n",
    "    # print(' finished ohe, mse: %.4f' % (mse_ohe))\n",
    "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, reg_type='ignore')\n",
    "    print(' finished ignore, mse: %.4f' % (mse_ig))\n",
    "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, reg_type='embed')\n",
    "    print(' finished embed, mse: %.4f' % (mse_em))\n",
    "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[1][0], sigmas[1][1], sigmas[1][2], sigmas[1][3],\n",
    "                              n_epochs_lmm, time_lmm]\n",
    "    # res.loc[next(counter)] = [i, 'ohe', mse_ohe, np.nan, np.nan, np.nan, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
    "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, np.nan, np.nan, np.nan, n_epochs_ig, time_ig]\n",
    "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, np.nan, np.nan, np.nan, n_epochs_em, time_em]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X, y = spotify.drop('danceability', axis=1), spotify['danceability']\n",
    "x_cols = [col for col in X.columns if not col.startswith('z')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../../results/res_spotify.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
