{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmnn.nn import reg_nn_ohe_or_ignore, reg_nn_embed, reg_nn_lmm\n",
    "from lmmnn.simulation import Count\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sgemm_product_dataset.zip can be downloaded from the UCI ML repository\n",
    "\n",
    "# Due to a TF bug there seems to be a memory leakage between LMMNN and other methods when run together,\n",
    "# and those other methods suffer in performance. Consider running LMMNNN separately.\n",
    "!unzip sgemm_product_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgemm = pd.read_csv('sgemm_product.csv')\n",
    "print(sgemm.shape)\n",
    "sgemm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgemm.insert(0, 'z0', np.arange(sgemm.shape[0]))\n",
    "sgemm_long = sgemm.melt(id_vars=sgemm.columns[:-4], value_vars=['Run1 (ms)', 'Run2 (ms)', 'Run3 (ms)', 'Run4 (ms)'], value_name='t')\n",
    "sgemm_long.drop(['variable'], axis=1, inplace=True)\n",
    "print(sgemm_long.shape)\n",
    "sgemm_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgemm_long.groupby('z0').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgemm_long['t'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgemm_long['t'] = np.log(sgemm_long['t'])\n",
    "sgemm_long['t'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [len(sgemm_long['z0'].unique())]\n",
    "x_cols = [col for col in sgemm_long.columns if col not in ['t', 'z0']]\n",
    "batch = 100\n",
    "epochs = 500\n",
    "patience = 10\n",
    "q_spatial = None\n",
    "n_neurons = [10, 5]\n",
    "dropout = None\n",
    "activation = 'relu'\n",
    "Z_non_linear = False\n",
    "Z_embed_dim_pct = 10\n",
    "mode = 'intercepts'\n",
    "n_sig2bs = 1\n",
    "n_sig2bs_spatial = 0\n",
    "est_cors = []\n",
    "dist_matrix = None\n",
    "time2measure_dict = None\n",
    "spatial_embed_neurons = None\n",
    "resultion = None\n",
    "verbose = True\n",
    "log_params = False\n",
    "idx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn(X_train, X_test, y_train, y_test, reg_type):\n",
    "    start = time.time()\n",
    "    if reg_type == 'ohe':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'lmm':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_lmm(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, dist_matrix, spatial_embed_neurons, verbose, Z_non_linear, Z_embed_dim_pct, log_params, idx)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose, ignore_RE=True)\n",
    "    elif reg_type == 'embed':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_embed(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    else:\n",
    "        raise ValueError(reg_type + 'is an unknown reg_type')\n",
    "    end = time.time()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.show()\n",
    "    return mse, sigmas, n_epochs, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est', 'sigma_b_est', 'n_epoch', 'time'])\n",
    "counter = 0\n",
    "\n",
    "def iterate_reg_types(X_train, X_test, y_train, y_test):\n",
    "    global counter\n",
    "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, reg_type='lmm')\n",
    "    print(' finished lmmnn, mse: %.4f' % (mse_lmm))\n",
    "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, reg_type='ignore')\n",
    "    print(' finished ignore, mse: %.4f' % (mse_ig))\n",
    "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, reg_type='embed')\n",
    "    print(' finished embed, mse: %.4f' % (mse_em))\n",
    "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[1][0], n_epochs_lmm, time_lmm]\n",
    "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, n_epochs_ig, time_ig]\n",
    "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, n_epochs_em, time_em]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "counter = Count().gen()\n",
    "X, y = sgemm_long.drop('t', axis=1), sgemm_long['t']\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../../results/res_sgemm.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "853417d72ad81a5e50a8613ae15c38dd8101027062a267a28f225259147f3710"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
