{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from lmmnn.layers import NLL\n",
    "from lmmnn.nn import calc_b_hat\n",
    "from lmmnn.menet import menet_fit, menet_predict\n",
    "from lmmnn.simulation import Count\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Reshape, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.keras.backend.set_floatx('float64')\n",
    "tf.keras.backend.floatx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: data_cleaned_train_comments_X.csv is the result of an ETL process described in Kalehbasti et. al. (2019), see our paper.\n",
    "# We followed the script in their Github repo exactly.\n",
    "\n",
    "# Due to a TF bug there seems to be a memory leakage between LMMNN and other methods when run together,\n",
    "# and those other methods suffer in performance. Consider running LMMNNN separately.\n",
    "\n",
    "path = 'AirBnbPricePrediction/Data/'\n",
    "X_train = pd.read_csv(path + 'data_cleaned_train_comments_X.csv')\n",
    "y_train = pd.read_csv(path + 'data_cleaned_train_y.csv').values\n",
    "y_train = y_train.reshape(len(y_train), )\n",
    "\n",
    "X_val = pd.read_csv(path + 'data_cleaned_val_comments_X.csv')\n",
    "y_val = pd.read_csv(path + 'data_cleaned_val_y.csv').values\n",
    "y_val = y_val.reshape(len(y_val), )\n",
    "\n",
    "X_test = pd.read_csv(path + 'data_cleaned_test_comments_X.csv')\n",
    "y_test = pd.read_csv(path + 'data_cleaned_test_y.csv').values\n",
    "y_test = y_test.reshape(len(y_test), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.load(path + 'selected_coefs.npy')\n",
    "col_set = set()\n",
    "\n",
    "for i in range(len(coeffs)):\n",
    "        if (coeffs[i]):\n",
    "            col_set.add(X_train.columns[i])\n",
    "X_train = X_train[list(col_set | set(['host_id']))]\n",
    "X_val = X_val[list(col_set | set(['host_id']))]\n",
    "X_test = X_test[list(col_set | set(['host_id']))]\n",
    "\n",
    "X = pd.concat([X_train, X_val, X_test], ignore_index=True)\n",
    "y = np.concatenate([y_train, y_val, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49976, 197)\n",
      "(49976,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant Adam params taken from original paper\n",
    "NUM_ITERATIONS = 1000\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DECAY_RATE = 0.0001\n",
    "\n",
    "# original paper Adam configuration:\n",
    "# adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "\n",
    "# some other params\n",
    "mode = 'intercepts'\n",
    "n_sig2bs = 1\n",
    "est_cors = []\n",
    "n_neurons = [20, 5]\n",
    "dropout = None\n",
    "activation = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cats = max([X_train['host_id'].max(), X_val['host_id'].max(), X_test['host_id'].max()]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'24-hour_check-in',\n",
       " 'Accessible-height_bed',\n",
       " 'Accessible-height_toilet',\n",
       " 'Air_conditioning',\n",
       " 'Apartment',\n",
       " 'Arverne.1',\n",
       " 'Astoria.1',\n",
       " 'Baby_bath',\n",
       " 'Babysitter_recommendations',\n",
       " 'Bathtub',\n",
       " 'Bay Ridge',\n",
       " 'Bed_linens',\n",
       " 'Bensonhurst',\n",
       " 'Boerum Hill',\n",
       " 'Borough Park',\n",
       " 'Boutique hotel',\n",
       " 'Breakfast',\n",
       " 'Bronx',\n",
       " 'Bronx.1',\n",
       " 'Brooklyn ',\n",
       " 'Brooklyn Heights',\n",
       " 'Brooklyn.1',\n",
       " 'Bushwick.1',\n",
       " 'Buzzer/wireless_intercom',\n",
       " 'Cable_TV',\n",
       " 'Carbon_monoxide_detector',\n",
       " 'Carroll Gardens',\n",
       " 'Cat(s)',\n",
       " 'Chelsea',\n",
       " 'Children’s_books_and_toys',\n",
       " 'Clinton Hill',\n",
       " 'Cobble Hill',\n",
       " 'Coffee_maker',\n",
       " 'Cooking_basics',\n",
       " 'Crib',\n",
       " 'Cypress Hills',\n",
       " 'DUMBO',\n",
       " 'Dishes_and_silverware',\n",
       " 'Dishwasher',\n",
       " 'Doorman',\n",
       " 'Downtown Brooklyn',\n",
       " 'Dryer',\n",
       " 'East Flatbush',\n",
       " 'East Harlem',\n",
       " 'East Village',\n",
       " 'Elevator',\n",
       " 'Elmhurst.1',\n",
       " 'Entire home/apt',\n",
       " 'Essentials',\n",
       " 'Ethernet_connection',\n",
       " 'Extra_pillows_and_blankets',\n",
       " 'Family/kid_friendly',\n",
       " 'Financial District',\n",
       " 'Fire_extinguisher',\n",
       " 'First_aid_kit',\n",
       " 'Flat_path_to_front_door',\n",
       " 'Flatbush',\n",
       " 'Flatiron District',\n",
       " 'Forest Hills.1',\n",
       " 'Fort Greene',\n",
       " 'Free_parking_on_premises',\n",
       " 'Free_street_parking',\n",
       " 'Game_console',\n",
       " 'Garden_or_backyard',\n",
       " 'Gowanus',\n",
       " 'Gramercy',\n",
       " 'Gravesend',\n",
       " 'Greenpoint',\n",
       " 'Greenwich Village',\n",
       " 'Guest suite',\n",
       " 'Gym',\n",
       " 'Hair_dryer',\n",
       " 'Handheld_shower_head',\n",
       " 'Hangers',\n",
       " 'Harlem.1',\n",
       " 'Heating',\n",
       " \"Hell's Kitchen\",\n",
       " 'High_chair',\n",
       " 'Host_greets_you',\n",
       " 'Hot_tub',\n",
       " 'Hot_water',\n",
       " 'Hotel',\n",
       " 'House',\n",
       " 'Indoor_fireplace',\n",
       " 'Internet',\n",
       " 'Inwood',\n",
       " 'Iron',\n",
       " 'Kensington',\n",
       " 'Keypad',\n",
       " 'Kitchen',\n",
       " 'Laptop_friendly_workspace',\n",
       " 'Little Italy',\n",
       " 'Lock_on_bedroom_door',\n",
       " 'Lockbox',\n",
       " 'Loft',\n",
       " 'Long Island City.1',\n",
       " 'Long_term_stays_allowed',\n",
       " 'Lower East Side',\n",
       " 'Luggage_dropoff_allowed',\n",
       " 'Manhattan',\n",
       " 'Microwave',\n",
       " 'Midtown',\n",
       " 'Midwood',\n",
       " 'Morningside Heights',\n",
       " 'NoHo',\n",
       " 'Nolita',\n",
       " 'Other',\n",
       " 'Oven',\n",
       " 'Pack_’n_Play/travel_crib',\n",
       " 'Paid_parking_off_premises',\n",
       " 'Paid_parking_on_premises',\n",
       " 'Park Slope',\n",
       " 'Patio_or_balcony',\n",
       " 'Pets_allowed',\n",
       " 'Pets_live_on_this_property',\n",
       " 'Pocket_wifi',\n",
       " 'Pool',\n",
       " 'Private_entrance',\n",
       " 'Private_living_room',\n",
       " 'Prospect Heights',\n",
       " 'Prospect-Lefferts Gardens',\n",
       " 'Queens',\n",
       " 'Queens.1',\n",
       " 'Real Bed',\n",
       " 'Refrigerator',\n",
       " 'Rego Park.1',\n",
       " 'Resort',\n",
       " 'Ridgewood.1',\n",
       " 'Riverdale',\n",
       " 'Rockaway Beach.1',\n",
       " 'Room-darkening_shades',\n",
       " 'Roosevelt Island',\n",
       " 'Safety_card',\n",
       " 'Self_check-in',\n",
       " 'Serviced apartment',\n",
       " 'Shampoo',\n",
       " 'Shared room',\n",
       " 'Smart_lock',\n",
       " 'Smoke_detector',\n",
       " 'Smoking_allowed',\n",
       " 'SoHo',\n",
       " 'South Slope',\n",
       " 'Springfield Gardens.1',\n",
       " 'Stair_gates',\n",
       " 'Staten Island',\n",
       " 'Staten Island.1',\n",
       " 'Stove',\n",
       " 'Suitable_for_events',\n",
       " 'Sunset Park',\n",
       " 'TV',\n",
       " 'Theater District',\n",
       " 'Townhouse',\n",
       " 'Tribeca',\n",
       " 'Upper West Side',\n",
       " 'Wakefield',\n",
       " 'Washer',\n",
       " 'Washington Heights',\n",
       " 'Well-lit_path_to_entrance',\n",
       " 'West Village',\n",
       " 'Wheelchair_accessible',\n",
       " 'Wifi',\n",
       " 'Williamsburg.1',\n",
       " 'Window_guards',\n",
       " 'Woodhaven.1',\n",
       " 'Woodside.1',\n",
       " 'a few days or more',\n",
       " 'accommodates',\n",
       " 'bedrooms',\n",
       " 'cleaning_fee',\n",
       " 'extra_people',\n",
       " 'facebook_verification',\n",
       " 'flexible',\n",
       " 'google_verification',\n",
       " 'government_id_verification',\n",
       " 'guests_included',\n",
       " 'host_has_profile_pic',\n",
       " 'host_is_superhost',\n",
       " 'host_since',\n",
       " 'identity_manual_verification',\n",
       " 'instant_bookable',\n",
       " 'longitude',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_value',\n",
       " 'reviews_per_month',\n",
       " 'reviews_verification',\n",
       " 'security_deposit',\n",
       " 'strict_14_with_grace_period',\n",
       " 'within a day',\n",
       " 'within a few hours',\n",
       " 'within an hour',\n",
       " 'work_email_verification'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rename(columns={'host_id': 'z0'}, inplace=True)\n",
    "y = y.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn_lmm(X_train, X_test, y_train, y_test, batch_size, epochs, patience, verbose):\n",
    "    X_input = Input(shape=(X_train[col_set].shape[1],))\n",
    "    y_true_input = Input(shape=(1,))\n",
    "    Z_input = Input(shape=(1,), dtype=tf.int64)\n",
    "    hidden1 = Dense(units=20, activation='relu', input_dim=len(X_train[col_set].values[0]))(X_input)\n",
    "    hidden2 = Dense(units=5, activation='relu')(hidden1)\n",
    "    y_pred_output = Dense(1, activation='linear')(hidden2)\n",
    "    nll = NLL(mode, 1.0, [1.0])(y_true_input, y_pred_output, [Z_input])\n",
    "    model = Model(inputs=[X_input, y_true_input, Z_input], outputs=nll)\n",
    "\n",
    "    adam = Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(optimizer= adam)\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
    "    \n",
    "    X_train.reset_index(inplace=True)\n",
    "    X_train.sort_values(by=['z0'], inplace=True)\n",
    "    y_train = y_train[X_train.index]\n",
    "    \n",
    "    history = model.fit([X_train[col_set], y_train, X_train['z0']], None, batch_size=batch_size, epochs=epochs,\n",
    "                        validation_split=0.1, callbacks=callbacks, verbose=verbose, shuffle=True)\n",
    "\n",
    "    sig2e_est, sig2b_ests, _ = model.layers[-1].get_vars()\n",
    "    y_pred_tr = model.predict([X_train[col_set], y_train, X_train['z0']]).reshape(X_train.shape[0])\n",
    "    b_hat = calc_b_hat(X_train, y_train, y_pred_tr, [n_cats], sig2e_est, sig2b_ests,\n",
    "                  False, model, None, mode, None, est_cors, None)\n",
    "    y_pred = model.predict([X_test[col_set], np.random.normal(size=y_test.shape), X_test['z0']]).reshape(X_test.shape[0]) + b_hat[X_test['z0']]\n",
    "    return y_pred, (sig2e_est, sig2b_ests), len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn_ignore(X_train, X_test, y_train, y_test, batch_size, epochs, patience, verbose):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units=20, activation='relu', input_dim=len(X_train[col_set].values[0])))\n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
    "    history = model.fit(X_train[col_set], y_train, epochs=epochs, verbose=verbose,\n",
    "                        batch_size=batch_size, validation_split = 0.1, callbacks=callbacks)\n",
    "    y_pred = model.predict(X_test[col_set]).reshape(X_test.shape[0])\n",
    "    return y_pred, (None, None), len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn_embed(X_train, X_test, y_train, y_test, batch_size, epochs, patience, verbose):\n",
    "    embed_dim = 100\n",
    "\n",
    "    X_input = Input(shape=(X_train[col_set].shape[1],))\n",
    "    Z_input = Input(shape=(1,))\n",
    "    embed = Embedding(n_cats, embed_dim, input_length = 1)(Z_input)\n",
    "    embed = Reshape(target_shape = (embed_dim,))(embed)\n",
    "    concat = Concatenate()([X_input, embed])\n",
    "    \n",
    "    hidden1 = Dense(units=20, activation='relu', input_dim=len(X_train[col_set].values[0]))(concat)\n",
    "    hidden2 = Dense(units=5, activation='relu')(hidden1)\n",
    "    output = Dense(1, activation='linear')(hidden2)\n",
    "\n",
    "    model = Model(inputs=[X_input, Z_input], outputs=output)\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
    "    history = model.fit([X_train[col_set], X_train['z0']], y_train, batch_size=batch_size, epochs=epochs,\n",
    "                        validation_split=0.1, callbacks=callbacks, verbose=verbose)\n",
    "    y_pred = model.predict([X_test[col_set], X_test['z0']]).reshape(X_test.shape[0])\n",
    "    return y_pred, (None, None), len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn_menet(X_train, X_test, y_train, y_test, batch_size, epochs, patience, verbose):\n",
    "    q = n_cats\n",
    "    clusters_train, clusters_test = X_train['z0'].values, X_test['z0'].values\n",
    "    X_train, X_test = X_train[col_set].values, X_test[col_set].values\n",
    "    # y_train, y_test = y_train.values, y_test.values\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    adam = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=DECAY_RATE, amsgrad=False)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "    model, b_hat, sig2e_est, n_epochs, _ = menet_fit(model, X_train, y_train, clusters_train, q, batch_size, epochs, patience, verbose=verbose)\n",
    "    y_pred = menet_predict(model, X_test, clusters_test, q, b_hat)\n",
    "    return y_pred, (sig2e_est, None), n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn(X_train, X_test, y_train, y_test, batch=30, epochs=100, patience=10, reg_type='ohe', verbose=False):\n",
    "    start = time.time()\n",
    "    if reg_type == 'ohe':\n",
    "        y_pred, sigmas, n_epochs = reg_nn_ohe(X_train, X_test, y_train, y_test, batch, epochs, patience, verbose)\n",
    "    elif reg_type == 'lmm':\n",
    "        y_pred, sigmas, n_epochs = reg_nn_lmm(X_train, X_test, y_train, y_test, batch, epochs, patience, verbose)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas, n_epochs = reg_nn_ignore(X_train, X_test, y_train, y_test, batch, epochs, patience, verbose)\n",
    "    elif reg_type == 'embed':\n",
    "        y_pred, sigmas, n_epochs = reg_nn_embed(X_train, X_test, y_train, y_test, batch, epochs, patience, verbose)\n",
    "    elif reg_type == 'menet':\n",
    "        y_pred, sigmas, n_epochs = reg_nn_menet(X_train, X_test, y_train, y_test, batch, epochs, patience, verbose)\n",
    "    else:\n",
    "      raise ValueError(reg_type + 'is an unknown reg_type')\n",
    "    end = time.time()\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    return mse, sigmas, n_epochs, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est', 'sigma_b0_est', 'n_epoch', 'time'])\n",
    "kf = KFold(n_splits=5)\n",
    "counter = Count().gen()\n",
    "x_cols = [col for col in X.columns if col != 'z0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_reg_types(X_train, X_test, y_train, y_test, counter, verbose):\n",
    "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, reg_type='lmm', verbose=verbose)\n",
    "    print(' finished lmm, mse: %.2f' % mse_lmm)\n",
    "    # mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, reg_type='ohe', verbose=verbose)\n",
    "    # print(' finished ohe, mse: %.2f' % mse_ohe)\n",
    "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, reg_type='ignore', verbose=verbose)\n",
    "    print(' finished ignore, mse: %.2f' % mse_ig)\n",
    "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, reg_type='embed', verbose=verbose)\n",
    "    print(' finished embed, mse: %.2f' % mse_em)\n",
    "    mse_me, sigmas_me, n_epochs_me, time_me = reg_nn(X_train, X_test, y_train, y_test, reg_type='menet', verbose=verbose)\n",
    "    print(' finished menet, mse: %.2f' % mse_me)\n",
    "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[1][0], n_epochs_lmm, time_lmm]\n",
    "    # res.loc[next(counter)] = [i, 'ohe', mse_ohe, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
    "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, n_epochs_ig, time_ig]\n",
    "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, n_epochs_em, time_em]\n",
    "    res.loc[next(counter)] = [i, 'menet', mse_me, sigmas_me[0], np.nan, n_epochs_me, time_me]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
    "    # scaler = StandardScaler()\n",
    "    # y_train = scaler.fit_transform(y_train.values.reshape(-1, 1)).reshape(X_train.shape[0])\n",
    "    # y_test = scaler.transform(y_test.values.reshape(-1, 1)).reshape(X_test.shape[0])\n",
    "    y_train = pd.Series(y_train, index=X_train.index)\n",
    "    y_test = pd.Series(y_test, index=X_test.index)\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test, counter, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../../results/res_airbnb.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "853417d72ad81a5e50a8613ae15c38dd8101027062a267a28f225259147f3710"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
