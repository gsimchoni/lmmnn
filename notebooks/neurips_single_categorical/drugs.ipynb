{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('../..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nz7b58k2WgZg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from lmmnn.layers import NLL\n",
        "from lmmnn.calc_b_hat import calc_b_hat\n",
        "from lmmnn.nn import process_one_hot_encoding\n",
        "from lmmnn.callbacks import EarlyStoppingWithSigmasConvergence\n",
        "from lmmnn.menet import menet_fit, menet_predict\n",
        "from lmmnn.simulation import Count\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Reshape, Concatenate, Input, Layer, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H_bWJVbwWgZg"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lsV53IjcawCl"
      },
      "outputs": [],
      "source": [
        "# The drugs_df CSV comes from simple binding the train and test TSVs from Gräßer et al. (2018),\n",
        "# available in the UCI ML repo, see our paper.\n",
        "drugs = pd.read_csv('drugs_df.csv')\n",
        "drugs.rename(columns={'drug_name':'z0'}, inplace=True)\n",
        "RE_col = 'z0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "3k-26fe-WgZh",
        "outputId": "7ae790f7-947b-4d13-ede7-02b982bf42b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>drug_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206461</td>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>9</td>\n",
              "      <td>May 20, 2012</td>\n",
              "      <td>27</td>\n",
              "      <td>3428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95260</td>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>8</td>\n",
              "      <td>April 27, 2010</td>\n",
              "      <td>192</td>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92703</td>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>5</td>\n",
              "      <td>December 14, 2009</td>\n",
              "      <td>17</td>\n",
              "      <td>1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>138000</td>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"This is my first time using any form of birth...</td>\n",
              "      <td>8</td>\n",
              "      <td>November 3, 2015</td>\n",
              "      <td>10</td>\n",
              "      <td>2456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35696</td>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Suboxone has completely turned my life around...</td>\n",
              "      <td>9</td>\n",
              "      <td>November 27, 2016</td>\n",
              "      <td>37</td>\n",
              "      <td>553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                  drugName                     condition  \\\n",
              "0  206461                 Valsartan  Left Ventricular Dysfunction   \n",
              "1   95260                Guanfacine                          ADHD   \n",
              "2   92703                    Lybrel                 Birth Control   \n",
              "3  138000                Ortho Evra                 Birth Control   \n",
              "4   35696  Buprenorphine / naloxone             Opiate Dependence   \n",
              "\n",
              "                                              review  rating  \\\n",
              "0  \"It has no side effect, I take it in combinati...       9   \n",
              "1  \"My son is halfway through his fourth week of ...       8   \n",
              "2  \"I used to take another oral contraceptive, wh...       5   \n",
              "3  \"This is my first time using any form of birth...       8   \n",
              "4  \"Suboxone has completely turned my life around...       9   \n",
              "\n",
              "                date  usefulCount  drug_name  \n",
              "0       May 20, 2012           27       3428  \n",
              "1     April 27, 2010          192       1542  \n",
              "2  December 14, 2009           17       1989  \n",
              "3   November 3, 2015           10       2456  \n",
              "4  November 27, 2016           37        553  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drugs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wtxphUSvWgZj"
      },
      "outputs": [],
      "source": [
        "max_features = 10000\n",
        "batch_size = 20\n",
        "epochs = 100\n",
        "patience = 5\n",
        "seq_len = 100\n",
        "words_embed_dim = 100\n",
        "Z_embed_dim = 10\n",
        "lstm_kernels = 64\n",
        "qs = [drugs['z0'].max() + 1]\n",
        "n_cats = qs\n",
        "q_spatial = None\n",
        "Z_non_linear = False\n",
        "mode = 'intercepts'\n",
        "Z_non_linear = False\n",
        "Z_embed_dim_pct = 10\n",
        "n_sig2bs = 1\n",
        "n_sig2bs_spatial = 0\n",
        "est_cors = []\n",
        "dist_matrix = None\n",
        "time2measure_dict = None\n",
        "spatial_embed_neurons = None\n",
        "resultion = None\n",
        "verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqg-BtSgWgZj",
        "outputId": "5eb3e3e9-a980-4051-a3fd-118d00e6be3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3671"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN2l6DPWWgZk",
        "outputId": "a024b5a3-b248-4127-ef47-8ab0996ea2ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drugs[RE_col].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn4vTU8cWgZk",
        "outputId": "ef020809-6d9e-405f-8e04-ddfd03bf452e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drugs[RE_col].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DWNy52KjWgZk"
      },
      "outputs": [],
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(drugs['review'])\n",
        "text_sequences = tokenizer.texts_to_sequences(drugs['review'])\n",
        "X = sequence.pad_sequences(text_sequences, padding='post', maxlen=seq_len)\n",
        "X = pd.DataFrame(X)\n",
        "x_cols = ['X' + str(i) for i in range(seq_len)]\n",
        "X.columns = x_cols\n",
        "X = pd.concat([X, drugs[RE_col]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8ftYpoyWgZk",
        "outputId": "35404164-c853-4dd5-95da-dbdd3ff15831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   5,   38,   28,   35,  198,    1,   45,    5,   15,  832,   12,\n",
              "       2948,   99,  149,    2, 3852, 1585,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.loc[0, x_cols].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGLYZYXUWgZl",
        "outputId": "592c3e48-8c4b-41ac-e530-3925d6166302"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.427009759930811"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "((X[x_cols] > 0).astype(int).sum(axis=1) == seq_len).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lJ4pVhZ1WgZl",
        "outputId": "4fcf6145-e9c1-4bac-8ec1-79a2390aedc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drugs.loc[0, 'review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRTKb4VWgZl",
        "outputId": "de37f9e5-7f09-4ca5-840d-de692da53f7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.word_index['it']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R3Q35JCiWgZl"
      },
      "outputs": [],
      "source": [
        "def lstm_ignore():\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    output = Dense(1)(x)\n",
        "    return Model(inputs=[input_layer], outputs=output)\n",
        "\n",
        "def lstm_lmmnn():\n",
        "    input_layer = Input(shape=(seq_len, ), dtype=tf.int32)\n",
        "    y_true_input = Input(shape=(1, ),)\n",
        "    Z_input = Input(shape=(1, ), dtype=tf.int64)\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    y_pred_output = Dense(1)(x)\n",
        "    nll = NLL('intercepts', 1.0, [1.0])(y_true_input, y_pred_output, [Z_input])\n",
        "    return Model(inputs=[input_layer, y_true_input, Z_input], outputs=nll)\n",
        "\n",
        "def lstm_embed():\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\n",
        "    Z_input = Input(shape=(1,))\n",
        "    embed = Embedding(n_cats, Z_embed_dim, input_length = 1)(Z_input)\n",
        "    embed = Reshape(target_shape = (Z_embed_dim, ))(embed)\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    concat = Concatenate()([x, embed])\n",
        "    output = Dense(1)(concat)\n",
        "    return Model(inputs=[input_layer, Z_input], outputs=output)\n",
        "\n",
        "def lstm_ohe(p):\n",
        "    input_layer = Input(shape=(None, ), dtype=tf.int32)\n",
        "    ohe_input = Input(shape=(p, ))\n",
        "    x = Embedding(max_features + 1, words_embed_dim)(input_layer)\n",
        "    x = LSTM(lstm_kernels)(x)\n",
        "    concat = Concatenate()([x, ohe_input])\n",
        "    output = Dense(1)(concat)\n",
        "    return Model(inputs=[input_layer, ohe_input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i1vjzVMuWgZn"
      },
      "outputs": [],
      "source": [
        "def reg_nn_ignore(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, verbose=False):\n",
        "    model = lstm_ignore()\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
        "    history = model.fit(X_train[x_cols], y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        validation_split=0.1, callbacks=callbacks, verbose=verbose)\n",
        "    y_pred = model.predict(X_test[x_cols]).reshape(X_test.shape[0])\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (None, None), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_ohe(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, verbose=False):\n",
        "    X_train, X_test = process_one_hot_encoding(X_train, X_test, x_cols)\n",
        "    model = lstm_ohe(X_train.drop(x_cols, axis=1).shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
        "    history = model.fit([X_train[x_cols], X_train.drop(x_cols, axis=1)], y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        validation_split=0.1, callbacks=callbacks, verbose=verbose)\n",
        "    y_pred = model.predict([X_test[x_cols], X_test.drop(x_cols, axis=1)]).reshape(X_test.shape[0])\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (None, None), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, verbose=False):\n",
        "    model = lstm_lmmnn()\n",
        "    model.compile(optimizer= 'adam')\n",
        "    \n",
        "    patience = epochs if patience is None else patience\n",
        "    # callbacks = [EarlyStoppingWithSigmasConvergence(patience=patience)]\n",
        "    callbacks = [EarlyStopping(patience=patience)]\n",
        "    X_train.reset_index(inplace=True)\n",
        "    y_train.reset_index(inplace=True, drop=True)\n",
        "    X_train.sort_values(by=[RE_col], inplace=True)\n",
        "    y_train = y_train[X_train.index]\n",
        "    history = model.fit([X_train[x_cols], y_train, X_train[RE_col]], None,\n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.1,\n",
        "                        callbacks=callbacks, verbose=verbose)\n",
        "    \n",
        "    sig2e_est, sig2b_ests, rho_ests, weibull_ests = model.layers[-1].get_vars()\n",
        "    sig2b_spatial_ests = []\n",
        "    ls = None\n",
        "    y_pred_tr = model.predict([X_train[x_cols], y_train, X_train[RE_col]]).reshape(X_train.shape[0])\n",
        "    y_pred_tr = np.clip(y_pred_tr, 1, 10)\n",
        "    b_hat = calc_b_hat(X_train, y_train, y_pred_tr, qs, q_spatial, sig2e_est, sig2b_ests, sig2b_spatial_ests,\n",
        "                Z_non_linear, model, ls, mode, rho_ests, est_cors, dist_matrix, weibull_ests)\n",
        "    dummy_y_test = np.random.normal(size=y_test.shape)\n",
        "    y_pred = model.predict([X_test[x_cols], dummy_y_test, X_test[RE_col]]).reshape(X_test.shape[0]) + b_hat[X_test[RE_col]]\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (sig2e_est, sig2b_ests), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, verbose=False):\n",
        "    model = lstm_embed()\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=epochs if patience is None else patience)]\n",
        "    history = model.fit([X_train[x_cols], X_train[RE_col]], y_train,\n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.1,\n",
        "                        callbacks=callbacks, verbose=verbose)\n",
        "    y_pred = model.predict([X_test[x_cols], X_test[RE_col]]).reshape(X_test.shape[0])\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (None, None), len(history.history['loss'])\n",
        "\n",
        "def reg_nn_menet(X_train, X_test, y_train, y_test, n_cats, batch_size, epochs, patience, verbose=False):\n",
        "    q = n_cats\n",
        "    clusters_train, clusters_test = X_train[RE_col].values, X_test[RE_col].values\n",
        "    X_train, X_test = X_train[x_cols].values, X_test[x_cols].values\n",
        "    y_train, y_test = y_train.values, y_test.values\n",
        "\n",
        "    model = lstm_ignore()\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    model, b_hat, sig2e_est, n_epochs, _ = menet_fit(model, X_train, y_train, clusters_train, q, batch_size, epochs, patience, verbose=verbose)\n",
        "    y_pred = menet_predict(model, X_test, clusters_test, q, b_hat)\n",
        "    y_pred = np.clip(y_pred, 1, 10)\n",
        "    return y_pred, (sig2e_est, None), n_epochs\n",
        "\n",
        "def reg_nn(X_train, X_test, y_train, y_test, n_cats, batch=batch_size, epochs=epochs, patience=patience, reg_type='ohe', verbose=False):    \n",
        "    start = time.time()\n",
        "    if reg_type == 'ohe':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_ohe(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, verbose)\n",
        "    elif reg_type == 'lmm':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_lmm(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, verbose)\n",
        "    elif reg_type == 'ignore':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_ignore(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, verbose)\n",
        "    elif reg_type == 'embed':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_embed(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, verbose)\n",
        "    elif reg_type == 'menet':\n",
        "        y_pred, sigmas, n_epochs = reg_nn_menet(X_train, X_test, y_train, y_test, n_cats, batch, epochs, patience, verbose)\n",
        "    else:\n",
        "        raise ValueError(reg_type + ' is an unknown reg_type')\n",
        "    end = time.time()\n",
        "    mse = np.mean((y_pred - y_test)**2)\n",
        "    return mse, sigmas, n_epochs, end - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l-LrfWXYWgZp",
        "outputId": "80aa6a65-7d16-4bb0-906a-fdb458d146f7"
      },
      "outputs": [],
      "source": [
        "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est', 'sigma_b_est', 'n_epochs', 'time'])\n",
        "counter = 0\n",
        "\n",
        "def iterate_reg_types(X_train, X_test, y_train, y_test, counter, verbose=False):\n",
        "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, qs[0], reg_type='ignore', verbose=verbose)\n",
        "    print(' finished ignore, mse: %.2f' % (mse_ig))\n",
        "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, qs[0], reg_type='lmm', verbose=verbose)\n",
        "    print(' finished lmm, mse: %.2f' % (mse_lmm))\n",
        "    mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, qs[0], reg_type='ohe', verbose=verbose)\n",
        "    print(' finished ohe, mse: %.2f' % (mse_ohe))\n",
        "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, qs[0], reg_type='embed', verbose=verbose)\n",
        "    print(' finished embed, mse: %.2f' % (mse_em))\n",
        "    mse_me, sigmas_me, n_epochs_me, time_me = reg_nn(X_train, X_test, y_train, y_test, qs[0], reg_type='menet', verbose=verbose)\n",
        "    print(' finished menet, mse: %.2f' % (mse_me))\n",
        "    res.loc[next(counter)] = [i, 'ohe', mse_ohe, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
        "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[1][0], n_epochs_lmm, time_lmm]\n",
        "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, n_epochs_ig, time_ig]\n",
        "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, n_epochs_em, time_em]\n",
        "    res.loc[next(counter)] = [i, 'menet', mse_me, sigmas_me[0], np.nan, n_epochs_me, time_me]\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "counter = Count().gen()\n",
        "y = drugs['rating']\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "    print('iteration %d' % i)\n",
        "    X_train, X_test, y_train, y_test = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
        "    iterate_reg_types(X_train, X_test, y_train, y_test, counter, verbose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "FPSjULlZWgZp",
        "outputId": "a750ed18-05a8-4357-f2fb-99e24105f506"
      },
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res.to_csv('../../results/res_drugs.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Drugs_Ratings_LSTM.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "853417d72ad81a5e50a8613ae15c38dd8101027062a267a28f225259147f3710"
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
