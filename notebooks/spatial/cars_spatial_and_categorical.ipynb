{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmnn.nn import reg_nn_ohe_or_ignore, reg_nn_embed, reg_nn_lmm, reg_nn_svdkl, reg_nn_cnn\n",
    "from lmmnn.simulation import Count\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used Cars from Craigslist dataset from Kaggle: https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data\n",
    "# Run cars_etl.R script\n",
    "cars = pd.read_csv('/content/drive/MyDrive/cars_df5.csv')\n",
    "print(cars.shape)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['price'] = np.log(cars['price'])\n",
    "cars['price'].plot(kind='hist', bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.groupby(['lat', 'long']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cars['location_id'].unique()))\n",
    "print(cars['location_id'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cars['model_id'].unique()))\n",
    "print(cars['model_id'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = cars.groupby(['location_id','lat', 'long']).size().index.to_frame().values\n",
    "dist_matrix = squareform(pdist(coords[:,1:])) ** 2\n",
    "print(dist_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.rename({'lat': 'D1', 'long': 'D2', 'location_id': 'z0', 'model_id': 'z1'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'spatial_and_categoricals'\n",
    "batch = 100\n",
    "epochs = 500\n",
    "patience = 10\n",
    "qs = [len(cars['z1'].unique())]\n",
    "q_spatial = len(cars['z0'].unique())\n",
    "n_neurons = [10, 3]\n",
    "dropout = []\n",
    "activation = 'relu'\n",
    "Z_non_linear = False\n",
    "Z_embed_dim_pct = 10\n",
    "n_sig2bs = 1\n",
    "n_sig2bs_spatial = 2\n",
    "est_cors = []\n",
    "time2measure_dict = None\n",
    "spatial_embed_neurons = None \n",
    "verbose = True\n",
    "log_params = False\n",
    "idx = None\n",
    "shuffle = False\n",
    "resolution = 100\n",
    "sample_n_train = 30000 # make sure sample_n_train is on the maximum it can get, I got to 30K (default 10K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn(X_train, X_test, y_train, y_test, reg_type):\n",
    "    start = time.time()\n",
    "    if reg_type == 'ohe':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'lmm':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_lmm(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, dist_matrix, spatial_embed_neurons,\n",
    "            verbose, Z_non_linear, Z_embed_dim_pct, log_params, idx, shuffle, sample_n_train)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose, ignore_RE=True)\n",
    "    elif reg_type == 'embed':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_embed(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'svdkl':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_svdkl(X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs,\n",
    "            patience, n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'cnn':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_cnn(X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs,\n",
    "            patience, n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, resolution, verbose)\n",
    "    else:\n",
    "        raise ValueError(reg_type + 'is an unknown reg_type')\n",
    "    end = time.time()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    y_pred = np.clip(y_pred, np.log(1000), np.log(300000))\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    plt.scatter(y_test, y_pred, alpha = 0.5)\n",
    "    plt.show()\n",
    "    return mse, sigmas, n_epochs, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est',\n",
    "                            'sigma_b0_est', 'sigma_b0_est_spatial', 'sigma_b1_est_spatial',\n",
    "                            'n_epoch', 'time'])\n",
    "def iterate_reg_types(X_train, X_test, y_train, y_test):\n",
    "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, reg_type='lmm')\n",
    "    print(' finished lmmnn, mse: %.4f' % (mse_lmm))\n",
    "    mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, reg_type='ohe')\n",
    "    print(' finished ohe, mse: %.4f' % (mse_ohe))\n",
    "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, reg_type='ignore')\n",
    "    print(' finished ignore, mse: %.4f' % (mse_ig))\n",
    "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, reg_type='embed')\n",
    "    print(' finished embed, mse: %.4f' % (mse_em))\n",
    "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[1][0], sigmas[2][0], sigmas[2][1], n_epochs_lmm, time_lmm]\n",
    "    res.loc[next(counter)] = [i, 'ohe', mse_ohe, np.nan, np.nan, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
    "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, np.nan, np.nan, n_epochs_ig, time_ig]\n",
    "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, np.nan, np.nan, n_epochs_em, time_em]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "counter = Count().gen()\n",
    "X, y = cars.drop(['price'], axis=1), cars['price']\n",
    "x_cols = [col for col in X.columns if col not in ['z0', 'z1']]\n",
    "x_cols_to_scale = [col for col in x_cols if col not in ['D1', 'D2']]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index].copy(), X.loc[test_index].copy(), y[train_index], y[test_index]\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../../results/res_cars_spatial_and_categorical.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
