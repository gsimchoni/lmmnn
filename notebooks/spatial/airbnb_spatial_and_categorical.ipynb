{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from lmmnn.nn import reg_nn_ohe_or_ignore, reg_nn_embed, reg_nn_lmm, reg_nn_svdkl, reg_nn_cnn\n",
    "from lmmnn.simulation import Count\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaned_train_comments_X.csv and the rest are the result of an ETL process described in Kalehbasti et. al. (2019).\n",
    "# We followed the script in their Github repo exactly.\n",
    "path = '../../AirBnbPricePrediction/Data'\n",
    "X_train = pd.read_csv(path + 'data_cleaned_train_comments_X.csv')\n",
    "y_train = pd.read_csv(path + 'data_cleaned_train_y.csv').values\n",
    "y_train = y_train.reshape(len(y_train), )\n",
    "\n",
    "X_val = pd.read_csv(path + 'data_cleaned_val_comments_X.csv')\n",
    "y_val = pd.read_csv(path + 'data_cleaned_val_y.csv').values\n",
    "y_val = y_val.reshape(len(y_val), )\n",
    "\n",
    "X_test = pd.read_csv(path + 'data_cleaned_test_comments_X.csv')\n",
    "y_test = pd.read_csv(path + 'data_cleaned_test_y.csv').values\n",
    "y_test = y_test.reshape(len(y_test), )\n",
    "\n",
    "coeffs = np.load(path + 'selected_coefs.npy')\n",
    "col_set = set()\n",
    "\n",
    "for i in range(len(coeffs)):\n",
    "    if coeffs[i]:\n",
    "        col_set.add(X_train.columns[i])\n",
    "X_train = X_train[list(col_set | set(['longitude', 'latitude', 'host_id']))]\n",
    "X_val = X_val[list(col_set | set(['longitude', 'latitude', 'host_id']))]\n",
    "X_test = X_test[list(col_set | set(['longitude', 'latitude', 'host_id']))]\n",
    "\n",
    "X = pd.concat([X_train, X_val, X_test], ignore_index=True)\n",
    "y = np.concatenate([y_train, y_val, y_test])\n",
    "\n",
    "X['id'] = np.arange(X.shape[0]) # longitude was already in col_set and we've added id column to be able to re-sort the data after the join\n",
    "\n",
    "print(X.shape) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins = 20) # listing price already logged\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['latitude', 'longitude']] = X[['latitude', 'longitude']].round(2)\n",
    "scaler = MinMaxScaler(feature_range=(-10, 10))\n",
    "X[['latitude', 'longitude']] = scaler.fit_transform(X[['latitude', 'longitude']])\n",
    "\n",
    "location_df = X.groupby(['latitude', 'longitude']).size().index.to_frame()\n",
    "location_df['location'] = np.arange(location_df.shape[0])\n",
    "location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.set_index(['latitude', 'longitude']).join(location_df[['location']]).reset_index().sort_values(by=['id']).drop(['id'], axis=1)\n",
    "X.index = np.arange(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X['location'].unique()))\n",
    "print(X['location'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = location_df[['latitude', 'longitude']].values\n",
    "dist_matrix = squareform(pdist(coords)) ** 2\n",
    "print(dist_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rename(columns={'latitude': 'D1', 'longitude': 'D2', 'location': 'z0', 'host_id': 'z1'}, inplace=True)\n",
    "\n",
    "# no colnames starting with z or D id using our functions\n",
    "X.columns = [col.lower() if col not in ['D1', 'D2'] else col for col in X.columns]\n",
    "print([col for col in X.columns if col.startswith('D')])\n",
    "print([col for col in X.columns if col.startswith('z')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'spatial_and_categoricals'\n",
    "batch = 100\n",
    "epochs = 500\n",
    "patience = 10\n",
    "qs = [len(X['z1'].unique())]\n",
    "q_spatial = len(X['z0'].unique())\n",
    "n_neurons = [10, 3]\n",
    "dropout = []\n",
    "activation = 'relu'\n",
    "Z_non_linear = False\n",
    "Z_embed_dim_pct = 10\n",
    "n_sig2bs = 1\n",
    "n_sig2bs_spatial = 2\n",
    "est_cors = []\n",
    "time2measure_dict = None\n",
    "spatial_embed_neurons = None \n",
    "verbose = True\n",
    "log_params = False\n",
    "idx = None\n",
    "shuffle = False\n",
    "resolution = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_nn(X_train, X_test, y_train, y_test, reg_type):\n",
    "    start = time.time()\n",
    "    if reg_type == 'ohe':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'lmm':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_lmm(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, dist_matrix, spatial_embed_neurons,\n",
    "            verbose, Z_non_linear, Z_embed_dim_pct, log_params, idx, shuffle)\n",
    "    elif reg_type == 'ignore':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_ohe_or_ignore(\n",
    "            X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose, ignore_RE=True)\n",
    "    elif reg_type == 'embed':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_embed(\n",
    "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'svdkl':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_svdkl(X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs,\n",
    "            patience, n_neurons, dropout, activation, mode, n_sig2bs, n_sig2bs_spatial, est_cors, verbose)\n",
    "    elif reg_type == 'cnn':\n",
    "        y_pred, sigmas, _, _, n_epochs = reg_nn_cnn(X_train, X_test, y_train, y_test, qs, x_cols, batch, epochs,\n",
    "            patience, n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, resolution, verbose)\n",
    "    else:\n",
    "        raise ValueError(reg_type + 'is an unknown reg_type')\n",
    "    end = time.time()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    plt.scatter(y_test, y_pred, alpha = 0.5)\n",
    "    plt.show()\n",
    "    return mse, sigmas, n_epochs, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['experiment', 'exp_type', 'mse', 'sigma_e_est', 'sigma_b0_est', 'sigma_b1_est', 'n_epoch', 'time'])\n",
    "counter = 0\n",
    "\n",
    "def iterate_reg_types(X_train, X_test, y_train, y_test):\n",
    "    mse_lmm, sigmas, n_epochs_lmm, time_lmm = reg_nn(X_train, X_test, y_train, y_test, reg_type='lmm')\n",
    "    print(' finished lmmnn, mse: %.4f' % (mse_lmm))\n",
    "    mse_ohe, _, n_epochs_ohe, time_ohe = reg_nn(X_train, X_test, y_train, y_test, reg_type='ohe')\n",
    "    print(' finished ohe, mse: %.4f' % (mse_ohe))\n",
    "    mse_ig, _, n_epochs_ig, time_ig = reg_nn(X_train, X_test, y_train, y_test, reg_type='ignore')\n",
    "    print(' finished ignore, mse: %.4f' % (mse_ig))\n",
    "    mse_em, _, n_epochs_em, time_em = reg_nn(X_train, X_test, y_train, y_test, reg_type='embed')\n",
    "    print(' finished embed, mse: %.4f' % (mse_em))\n",
    "    res.loc[next(counter)] = [i, 'lmm', mse_lmm, sigmas[0], sigmas[2][0], sigmas[2][1], n_epochs_lmm, time_lmm]\n",
    "    res.loc[next(counter)] = [i, 'ohe', mse_ohe, np.nan, np.nan, np.nan, n_epochs_ohe, time_ohe]\n",
    "    res.loc[next(counter)] = [i, 'ignore', mse_ig, np.nan, np.nan, np.nan, n_epochs_ig, time_ig]\n",
    "    res.loc[next(counter)] = [i, 'embed', mse_em, np.nan, np.nan, np.nan, n_epochs_em, time_em]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "counter = Count().gen()\n",
    "\n",
    "x_cols = [col for col in X.columns if col not in ['z0']]\n",
    "x_cols_to_scale = [col for col in x_cols if col not in ['D1', 'D2']]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    print('iteration %d' % i)\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_index].copy(), X.loc[test_index].copy(), y[train_index], y[test_index]\n",
    "    y_train = pd.Series(y_train, index=X_train.index)\n",
    "    y_test = pd.Series(y_test, index=X_test.index)\n",
    "    iterate_reg_types(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../../results/res_airbnb_spatial_and_categorical.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
